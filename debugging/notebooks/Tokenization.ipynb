{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "induced-detroit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-15 12:08:15 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2021-03-15 12:08:15 INFO: Use device: cpu\n",
      "2021-03-15 12:08:15 INFO: Loading: tokenize\n",
      "2021-03-15 12:08:15 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Setup stuff\n",
    "import spacy\n",
    "import tabulate\n",
    "SPACY_PIPELINE = spacy.load(\"en_core_web_lg\")\n",
    "import stanza\n",
    "STANZA_PIPELINE = stanza.Pipeline(lang='en', processors='tokenize')\n",
    "import nltk\n",
    "from termcolor import colored\n",
    "import pandas as pd\n",
    "\n",
    "def tokenize_spacy(text):\n",
    "    doc = SPACY_PIPELINE(text.replace(\"\\n\", \" \"))\n",
    "    sentences = []\n",
    "    for sentence in doc.sents:\n",
    "        sentences.append([token.text for token in sentence])\n",
    "    return sentences\n",
    "\n",
    "def tokenize_stanza(text):\n",
    "    doc = STANZA_PIPELINE(text.replace(\"\\n\", \" \"))\n",
    "    sentences = []\n",
    "    for sentence in doc.sentences:\n",
    "        sentences.append([word.text for word in sentence.tokens])\n",
    "    return sentences\n",
    "\n",
    "def tokenize_nltk(text):\n",
    "    return [nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(text.replace(\"\\n\", \" \"))]\n",
    "\n",
    "def split_tokenize(tokenize_fn, text):\n",
    "    maybe_sents = text.split(\"\\n\")\n",
    "    overall_sents = []\n",
    "    for sent in maybe_sents:\n",
    "        overall_sents += tokenize_fn(sent)\n",
    "    return overall_sents\n",
    "\n",
    "COLORS = [\"red\", \"blue\"]\n",
    "def build_column(tokenized_sentences):\n",
    "    column = []\n",
    "    for i, sentence in enumerate(tokenized_sentences):\n",
    "        color = COLORS[i%2]\n",
    "        column += [colored(token, color) for token in sentence]\n",
    "    return column\n",
    "\n",
    "def build_tokenized_col(tokenize_fn, text):\n",
    "    tokenized = tokenize_fn(text)\n",
    "    return build_column(tokenized)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unlimited-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cols(text):\n",
    "    spacy_col = build_tokenized_col(tokenize_spacy, text)\n",
    "    stanza_col = build_tokenized_col(tokenize_stanza, text)\n",
    "    nltk_col = build_tokenized_col(tokenize_nltk, text)\n",
    "    \n",
    "    spacy_2_col = build_tokenized_col(lambda z:split_tokenize(tokenize_spacy, z), text)\n",
    "    stanza_2_col = build_tokenized_col(lambda z:split_tokenize(tokenize_stanza, z), text)\n",
    "    nltk_2_col = build_tokenized_col(lambda z:split_tokenize(tokenize_nltk, z), text)\n",
    "\n",
    "    max_len = max([len(x) for x in [spacy_col, stanza_col, nltk_col, spacy_2_col, stanza_2_col, nltk_2_col]])\n",
    "\n",
    "    spacy_col += [\"\"] * (max_len - len(spacy_col))\n",
    "    spacy_2_col += [\"\"] * (max_len - len(spacy_2_col))\n",
    "    stanza_col += [\"\"] * (max_len - len(stanza_col))\n",
    "    stanza_2_col += [\"\"] * (max_len - len(stanza_2_col))\n",
    "    nltk_col += [\"\"] * (max_len - len(nltk_col))\n",
    "    nltk_2_col += [\"\"] * (max_len - len(nltk_2_col))\n",
    "    return spacy_col, spacy_2_col, stanza_col, stanza_2_col, nltk_col, nltk_2_col\n",
    "\n",
    "\n",
    "def make_table(text):\n",
    "    return tabulate.tabulate(\n",
    "        zip(*make_cols(text)),\n",
    "        headers = [\"Spacy\", \"Spacy split\", \"Stanza\", \"Stanza split\", \"NLTK\", \"NLTK split\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liberal-score",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy         Spacy split    Stanza        Stanza split    NLTK          NLTK split\n",
      "------------  -------------  ------------  --------------  ------------  ------------\n",
      "\u001b[31mThe\u001b[0m           \u001b[31mThe\u001b[0m            \u001b[31mThe\u001b[0m           \u001b[31mThe\u001b[0m             \u001b[31mThe\u001b[0m           \u001b[31mThe\u001b[0m\n",
      "\u001b[31mpaper\u001b[0m         \u001b[31mpaper\u001b[0m          \u001b[31mpaper\u001b[0m         \u001b[31mpaper\u001b[0m           \u001b[31mpaper\u001b[0m         \u001b[31mpaper\u001b[0m\n",
      "\u001b[31mdescribes\u001b[0m     \u001b[31mdescribes\u001b[0m      \u001b[31mdescribes\u001b[0m     \u001b[31mdescribes\u001b[0m       \u001b[31mdescribes\u001b[0m     \u001b[31mdescribes\u001b[0m\n",
      "\u001b[31ma\u001b[0m             \u001b[31ma\u001b[0m              \u001b[31ma\u001b[0m             \u001b[31ma\u001b[0m               \u001b[31ma\u001b[0m             \u001b[31ma\u001b[0m\n",
      "\u001b[31mnew\u001b[0m           \u001b[31mnew\u001b[0m            \u001b[31mnew\u001b[0m           \u001b[31mnew\u001b[0m             \u001b[31mnew\u001b[0m           \u001b[31mnew\u001b[0m\n",
      "\u001b[31mstudy\u001b[0m         \u001b[31mstudy\u001b[0m          \u001b[31mstudy\u001b[0m         \u001b[31mstudy\u001b[0m           \u001b[31mstudy\u001b[0m         \u001b[31mstudy\u001b[0m\n",
      "\u001b[31mabout\u001b[0m         \u001b[31mabout\u001b[0m          \u001b[31mabout\u001b[0m         \u001b[31mabout\u001b[0m           \u001b[31mabout\u001b[0m         \u001b[31mabout\u001b[0m\n",
      "\u001b[31mhow\u001b[0m           \u001b[31mhow\u001b[0m            \u001b[31mhow\u001b[0m           \u001b[31mhow\u001b[0m             \u001b[31mhow\u001b[0m           \u001b[31mhow\u001b[0m\n",
      "\u001b[31mto\u001b[0m            \u001b[31mto\u001b[0m             \u001b[31mto\u001b[0m            \u001b[31mto\u001b[0m              \u001b[31mto\u001b[0m            \u001b[31mto\u001b[0m\n",
      "\u001b[31mmake\u001b[0m          \u001b[31mmake\u001b[0m           \u001b[31mmake\u001b[0m          \u001b[31mmake\u001b[0m            \u001b[31mmake\u001b[0m          \u001b[31mmake\u001b[0m\n",
      "\u001b[31mdialogs\u001b[0m       \u001b[31mdialogs\u001b[0m        \u001b[31mdialogs\u001b[0m       \u001b[31mdialogs\u001b[0m         \u001b[31mdialogs\u001b[0m       \u001b[31mdialogs\u001b[0m\n",
      "\u001b[31mmore\u001b[0m          \u001b[31mmore\u001b[0m           \u001b[31mmore\u001b[0m          \u001b[31mmore\u001b[0m            \u001b[31mmore\u001b[0m          \u001b[31mmore\u001b[0m\n",
      "\u001b[31mempathetic\u001b[0m    \u001b[31mempathetic\u001b[0m     \u001b[31mempathetic\u001b[0m    \u001b[31mempathetic\u001b[0m      \u001b[31mempathetic\u001b[0m    \u001b[31mempathetic\u001b[0m\n",
      "\u001b[31m.\u001b[0m             \u001b[31m.\u001b[0m              \u001b[31m.\u001b[0m             \u001b[31m.\u001b[0m               \u001b[31m.\u001b[0m             \u001b[31m.\u001b[0m\n",
      "\u001b[34mThe\u001b[0m           \u001b[34mThe\u001b[0m            \u001b[34mThe\u001b[0m           \u001b[34mThe\u001b[0m             \u001b[34mThe\u001b[0m           \u001b[34mThe\u001b[0m\n",
      "\u001b[34mwork\u001b[0m          \u001b[34mwork\u001b[0m           \u001b[34mwork\u001b[0m          \u001b[34mwork\u001b[0m            \u001b[34mwork\u001b[0m          \u001b[34mwork\u001b[0m\n",
      "\u001b[34mintroduced\u001b[0m    \u001b[34mintroduced\u001b[0m     \u001b[34mintroduced\u001b[0m    \u001b[34mintroduced\u001b[0m      \u001b[34mintroduced\u001b[0m    \u001b[34mintroduced\u001b[0m\n",
      "\u001b[34ma\u001b[0m             \u001b[34ma\u001b[0m              \u001b[34ma\u001b[0m             \u001b[34ma\u001b[0m               \u001b[34ma\u001b[0m             \u001b[34ma\u001b[0m\n",
      "\u001b[34mnew\u001b[0m           \u001b[34mnew\u001b[0m            \u001b[34mnew\u001b[0m           \u001b[34mnew\u001b[0m             \u001b[34mnew\u001b[0m           \u001b[34mnew\u001b[0m\n",
      "\u001b[34mdataset\u001b[0m       \u001b[34mdataset\u001b[0m        \u001b[34mdataset\u001b[0m       \u001b[34mdataset\u001b[0m         \u001b[34mdataset\u001b[0m       \u001b[34mdataset\u001b[0m\n",
      "\u001b[34mof\u001b[0m            \u001b[34mof\u001b[0m             \u001b[34mof\u001b[0m            \u001b[34mof\u001b[0m              \u001b[34mof\u001b[0m            \u001b[34mof\u001b[0m\n",
      "\u001b[34m25k\u001b[0m           \u001b[34m25k\u001b[0m            \u001b[34m25\u001b[0m            \u001b[34m25\u001b[0m              \u001b[34m25k\u001b[0m           \u001b[34m25k\u001b[0m\n",
      "\u001b[34mdialogs\u001b[0m       \u001b[34mdialogs\u001b[0m        \u001b[34mk\u001b[0m             \u001b[34mk\u001b[0m               \u001b[34mdialogs\u001b[0m       \u001b[34mdialogs\u001b[0m\n",
      "\u001b[34mdesigned\u001b[0m      \u001b[34mdesigned\u001b[0m       \u001b[34mdialogs\u001b[0m       \u001b[34mdialogs\u001b[0m         \u001b[34mdesigned\u001b[0m      \u001b[34mdesigned\u001b[0m\n",
      "\u001b[34mto\u001b[0m            \u001b[34mto\u001b[0m             \u001b[34mdesigned\u001b[0m      \u001b[34mdesigned\u001b[0m        \u001b[34mto\u001b[0m            \u001b[34mto\u001b[0m\n",
      "\u001b[34mevaluate\u001b[0m      \u001b[34mevaluate\u001b[0m       \u001b[34mto\u001b[0m            \u001b[34mto\u001b[0m              \u001b[34mevaluate\u001b[0m      \u001b[34mevaluate\u001b[0m\n",
      "\u001b[34mthe\u001b[0m           \u001b[34mthe\u001b[0m            \u001b[34mevaluate\u001b[0m      \u001b[34mevaluate\u001b[0m        \u001b[34mthe\u001b[0m           \u001b[34mthe\u001b[0m\n",
      "\u001b[34mrole\u001b[0m          \u001b[31mrole\u001b[0m           \u001b[34mthe\u001b[0m           \u001b[34mthe\u001b[0m             \u001b[34mrole\u001b[0m          \u001b[31mrole\u001b[0m\n",
      "\u001b[34mthat\u001b[0m          \u001b[31mthat\u001b[0m           \u001b[34mrole\u001b[0m          \u001b[31mrole\u001b[0m            \u001b[34mthat\u001b[0m          \u001b[31mthat\u001b[0m\n",
      "\u001b[34mempathy\u001b[0m       \u001b[31mempathy\u001b[0m        \u001b[34mthat\u001b[0m          \u001b[31mthat\u001b[0m            \u001b[34mempathy\u001b[0m       \u001b[31mempathy\u001b[0m\n",
      "\u001b[34mrecognition\u001b[0m   \u001b[31mrecognition\u001b[0m    \u001b[34mempathy\u001b[0m       \u001b[31mempathy\u001b[0m         \u001b[34mrecognition\u001b[0m   \u001b[31mrecognition\u001b[0m\n",
      "\u001b[34mmay\u001b[0m           \u001b[31mmay\u001b[0m            \u001b[34mrecognition\u001b[0m   \u001b[31mrecognition\u001b[0m     \u001b[34mmay\u001b[0m           \u001b[31mmay\u001b[0m\n",
      "\u001b[34mplay\u001b[0m          \u001b[31mplay\u001b[0m           \u001b[34mmay\u001b[0m           \u001b[31mmay\u001b[0m             \u001b[34mplay\u001b[0m          \u001b[31mplay\u001b[0m\n",
      "\u001b[34min\u001b[0m            \u001b[31min\u001b[0m             \u001b[34mplay\u001b[0m          \u001b[31mplay\u001b[0m            \u001b[34min\u001b[0m            \u001b[31min\u001b[0m\n",
      "\u001b[34mgenerating\u001b[0m    \u001b[31mgenerating\u001b[0m     \u001b[34min\u001b[0m            \u001b[31min\u001b[0m              \u001b[34mgenerating\u001b[0m    \u001b[31mgenerating\u001b[0m\n",
      "\u001b[34mbetter\u001b[0m        \u001b[31mbetter\u001b[0m         \u001b[34mgenerating\u001b[0m    \u001b[31mgenerating\u001b[0m      \u001b[34mbetter\u001b[0m        \u001b[31mbetter\u001b[0m\n",
      "\u001b[34mresponses\u001b[0m     \u001b[31mresponses\u001b[0m      \u001b[34mbetter\u001b[0m        \u001b[31mbetter\u001b[0m          \u001b[34mresponses\u001b[0m     \u001b[31mresponses\u001b[0m\n",
      "\u001b[34mtuned\u001b[0m         \u001b[34mtuned\u001b[0m          \u001b[34mresponses\u001b[0m     \u001b[31mresponses\u001b[0m       \u001b[34mtuned\u001b[0m         \u001b[34mtuned\u001b[0m\n",
      "\u001b[34mto\u001b[0m            \u001b[34mto\u001b[0m             \u001b[34mtuned\u001b[0m         \u001b[34mtuned\u001b[0m           \u001b[34mto\u001b[0m            \u001b[34mto\u001b[0m\n",
      "\u001b[34mthe\u001b[0m           \u001b[34mthe\u001b[0m            \u001b[34mto\u001b[0m            \u001b[34mto\u001b[0m              \u001b[34mthe\u001b[0m           \u001b[34mthe\u001b[0m\n",
      "\u001b[34mfeeling\u001b[0m       \u001b[34mfeeling\u001b[0m        \u001b[34mthe\u001b[0m           \u001b[34mthe\u001b[0m             \u001b[34mfeeling\u001b[0m       \u001b[34mfeeling\u001b[0m\n",
      "\u001b[34mof\u001b[0m            \u001b[34mof\u001b[0m             \u001b[34mfeeling\u001b[0m       \u001b[34mfeeling\u001b[0m         \u001b[34mof\u001b[0m            \u001b[34mof\u001b[0m\n",
      "\u001b[34mthe\u001b[0m           \u001b[34mthe\u001b[0m            \u001b[34mof\u001b[0m            \u001b[34mof\u001b[0m              \u001b[34mthe\u001b[0m           \u001b[34mthe\u001b[0m\n",
      "\u001b[34mconversation\u001b[0m  \u001b[34mconversation\u001b[0m   \u001b[34mthe\u001b[0m           \u001b[34mthe\u001b[0m             \u001b[34mconversation\u001b[0m  \u001b[34mconversation\u001b[0m\n",
      "\u001b[34mpartner\u001b[0m       \u001b[34mpartner\u001b[0m        \u001b[34mconversation\u001b[0m  \u001b[34mconversation\u001b[0m    \u001b[34mpartner\u001b[0m       \u001b[34mpartner\u001b[0m\n",
      "\u001b[34m.\u001b[0m             \u001b[34m.\u001b[0m              \u001b[34mpartner\u001b[0m       \u001b[34mpartner\u001b[0m         \u001b[34m.\u001b[0m             \u001b[34m.\u001b[0m\n",
      "\u001b[31m \u001b[0m             \u001b[31m \u001b[0m              \u001b[34m.\u001b[0m             \u001b[34m.\u001b[0m               \u001b[31mSeveral\u001b[0m       \u001b[31mSeveral\u001b[0m\n",
      "\u001b[34mSeveral\u001b[0m       \u001b[34mSeveral\u001b[0m        \u001b[31mSeveral\u001b[0m       \u001b[31mSeveral\u001b[0m         \u001b[31mmodel\u001b[0m         \u001b[31mmodel\u001b[0m\n",
      "\u001b[34mmodel\u001b[0m         \u001b[34mmodel\u001b[0m          \u001b[31mmodel\u001b[0m         \u001b[31mmodel\u001b[0m           \u001b[31mset-ups\u001b[0m       \u001b[34mset-ups\u001b[0m\n",
      "\u001b[34mset\u001b[0m           \u001b[31mset\u001b[0m            \u001b[31mset-ups\u001b[0m       \u001b[34mset-ups\u001b[0m         \u001b[31m,\u001b[0m             \u001b[34m,\u001b[0m\n",
      "\u001b[34m-\u001b[0m             \u001b[31m-\u001b[0m              \u001b[31m,\u001b[0m             \u001b[34m,\u001b[0m               \u001b[31mand\u001b[0m           \u001b[34mand\u001b[0m\n",
      "\u001b[34mups\u001b[0m           \u001b[31mups\u001b[0m            \u001b[31mand\u001b[0m           \u001b[34mand\u001b[0m             \u001b[31mmany\u001b[0m          \u001b[34mmany\u001b[0m\n",
      "\u001b[34m,\u001b[0m             \u001b[31m,\u001b[0m              \u001b[31mmany\u001b[0m          \u001b[34mmany\u001b[0m            \u001b[31msecondary\u001b[0m     \u001b[34msecondary\u001b[0m\n",
      "\u001b[34mand\u001b[0m           \u001b[31mand\u001b[0m            \u001b[31msecondary\u001b[0m     \u001b[34msecondary\u001b[0m       \u001b[31moptions\u001b[0m       \u001b[34moptions\u001b[0m\n",
      "\u001b[34mmany\u001b[0m          \u001b[31mmany\u001b[0m           \u001b[31moptions\u001b[0m       \u001b[34moptions\u001b[0m         \u001b[31mof\u001b[0m            \u001b[34mof\u001b[0m\n",
      "\u001b[34msecondary\u001b[0m     \u001b[31msecondary\u001b[0m      \u001b[31mof\u001b[0m            \u001b[34mof\u001b[0m              \u001b[31mthe\u001b[0m           \u001b[34mthe\u001b[0m\n",
      "\u001b[34moptions\u001b[0m       \u001b[31moptions\u001b[0m        \u001b[31mthe\u001b[0m           \u001b[34mthe\u001b[0m             \u001b[31mset-ups\u001b[0m       \u001b[34mset-ups\u001b[0m\n",
      "\u001b[34mof\u001b[0m            \u001b[31mof\u001b[0m             \u001b[31mset-ups\u001b[0m       \u001b[34mset-ups\u001b[0m         \u001b[31mare\u001b[0m           \u001b[34mare\u001b[0m\n",
      "\u001b[34mthe\u001b[0m           \u001b[31mthe\u001b[0m            \u001b[31mare\u001b[0m           \u001b[34mare\u001b[0m             \u001b[31mevaluated\u001b[0m     \u001b[34mevaluated\u001b[0m\n",
      "\u001b[34mset\u001b[0m           \u001b[31mset\u001b[0m            \u001b[31mevaluated\u001b[0m     \u001b[34mevaluated\u001b[0m       \u001b[31m.\u001b[0m             \u001b[34m.\u001b[0m\n",
      "\u001b[34m-\u001b[0m             \u001b[31m-\u001b[0m              \u001b[31m.\u001b[0m             \u001b[34m.\u001b[0m\n",
      "\u001b[34mups\u001b[0m           \u001b[31mups\u001b[0m\n",
      "\u001b[34mare\u001b[0m           \u001b[31mare\u001b[0m\n",
      "\u001b[34mevaluated\u001b[0m     \u001b[31mevaluated\u001b[0m\n",
      "\u001b[34m.\u001b[0m             \u001b[31m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "text = \"The paper describes a new study about how to make dialogs more empathetic.\\nThe work introduced a new dataset of 25k dialogs designed to evaluate the\\nrole that empathy recognition may play in generating better responses\\ntuned to the feeling of the conversation partner.  Several model\\nset-ups, and many secondary options of the set-ups are evaluated.\"\n",
    "print(make_table(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "parental-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy         Spacy split    Stanza        Stanza split    NLTK          NLTK split\n",
      "------------  -------------  ------------  --------------  ------------  ------------\n",
      "\u001b[31mPros\u001b[0m          \u001b[31mPros\u001b[0m           \u001b[31mPros\u001b[0m          \u001b[31mPros\u001b[0m            \u001b[31mPros\u001b[0m          \u001b[31mPros\u001b[0m\n",
      "\u001b[31m:\u001b[0m             \u001b[31m:\u001b[0m              \u001b[31m:\u001b[0m             \u001b[31m:\u001b[0m               \u001b[31m:\u001b[0m             \u001b[31m:\u001b[0m\n",
      "\u001b[31m-\u001b[0m             \u001b[34m-\u001b[0m              \u001b[31m-\u001b[0m             \u001b[34m-\u001b[0m               \u001b[31m-\u001b[0m             \u001b[34m-\u001b[0m\n",
      "\u001b[31mThe\u001b[0m           \u001b[34mThe\u001b[0m            \u001b[31mThe\u001b[0m           \u001b[31mThe\u001b[0m             \u001b[31mThe\u001b[0m           \u001b[34mThe\u001b[0m\n",
      "\u001b[31mderivation\u001b[0m    \u001b[34mderivation\u001b[0m     \u001b[31mderivation\u001b[0m    \u001b[31mderivation\u001b[0m      \u001b[31mderivation\u001b[0m    \u001b[34mderivation\u001b[0m\n",
      "\u001b[31mof\u001b[0m            \u001b[34mof\u001b[0m             \u001b[31mof\u001b[0m            \u001b[31mof\u001b[0m              \u001b[31mof\u001b[0m            \u001b[34mof\u001b[0m\n",
      "\u001b[31mthe\u001b[0m           \u001b[34mthe\u001b[0m            \u001b[31mthe\u001b[0m           \u001b[31mthe\u001b[0m             \u001b[31mthe\u001b[0m           \u001b[34mthe\u001b[0m\n",
      "\u001b[31mloss\u001b[0m          \u001b[34mloss\u001b[0m           \u001b[31mloss\u001b[0m          \u001b[31mloss\u001b[0m            \u001b[31mloss\u001b[0m          \u001b[34mloss\u001b[0m\n",
      "\u001b[31mshows\u001b[0m         \u001b[34mshows\u001b[0m          \u001b[31mshows\u001b[0m         \u001b[31mshows\u001b[0m           \u001b[31mshows\u001b[0m         \u001b[34mshows\u001b[0m\n",
      "\u001b[31ma\u001b[0m             \u001b[34ma\u001b[0m              \u001b[31ma\u001b[0m             \u001b[31ma\u001b[0m               \u001b[31ma\u001b[0m             \u001b[34ma\u001b[0m\n",
      "\u001b[31mnice\u001b[0m          \u001b[34mnice\u001b[0m           \u001b[31mnice\u001b[0m          \u001b[31mnice\u001b[0m            \u001b[31mnice\u001b[0m          \u001b[34mnice\u001b[0m\n",
      "\u001b[31mlink\u001b[0m          \u001b[34mlink\u001b[0m           \u001b[31mlink\u001b[0m          \u001b[31mlink\u001b[0m            \u001b[31mlink\u001b[0m          \u001b[34mlink\u001b[0m\n",
      "\u001b[31mbetween\u001b[0m       \u001b[34mbetween\u001b[0m        \u001b[31mbetween\u001b[0m       \u001b[31mbetween\u001b[0m         \u001b[31mbetween\u001b[0m       \u001b[34mbetween\u001b[0m\n",
      "\u001b[31mMutual\u001b[0m        \u001b[34mMutual\u001b[0m         \u001b[31mMutual\u001b[0m        \u001b[31mMutual\u001b[0m          \u001b[31mMutual\u001b[0m        \u001b[34mMutual\u001b[0m\n",
      "\u001b[31minformation\u001b[0m   \u001b[34minformation\u001b[0m    \u001b[31minformation\u001b[0m   \u001b[31minformation\u001b[0m     \u001b[31minformation\u001b[0m   \u001b[34minformation\u001b[0m\n",
      "\u001b[31mand\u001b[0m           \u001b[34mand\u001b[0m            \u001b[31mand\u001b[0m           \u001b[31mand\u001b[0m             \u001b[31mand\u001b[0m           \u001b[34mand\u001b[0m\n",
      "\u001b[31mtotal\u001b[0m         \u001b[34mtotal\u001b[0m          \u001b[31mtotal\u001b[0m         \u001b[31mtotal\u001b[0m           \u001b[31mtotal\u001b[0m         \u001b[34mtotal\u001b[0m\n",
      "\u001b[31mcorrelation\u001b[0m   \u001b[34mcorrelation\u001b[0m    \u001b[31mcorrelation\u001b[0m   \u001b[31mcorrelation\u001b[0m     \u001b[31mcorrelation\u001b[0m   \u001b[34mcorrelation\u001b[0m\n",
      "\u001b[31min\u001b[0m            \u001b[34min\u001b[0m             \u001b[31min\u001b[0m            \u001b[31min\u001b[0m              \u001b[31min\u001b[0m            \u001b[34min\u001b[0m\n",
      "\u001b[31mthe\u001b[0m           \u001b[34mthe\u001b[0m            \u001b[31mthe\u001b[0m           \u001b[31mthe\u001b[0m             \u001b[31mthe\u001b[0m           \u001b[34mthe\u001b[0m\n",
      "\u001b[31mlatents\u001b[0m       \u001b[34mlatents\u001b[0m        \u001b[31mlatents\u001b[0m       \u001b[31mlatents\u001b[0m         \u001b[31mlatents\u001b[0m       \u001b[34mlatents\u001b[0m\n",
      "\u001b[31m.\u001b[0m             \u001b[34m.\u001b[0m              \u001b[31m.\u001b[0m             \u001b[31m.\u001b[0m               \u001b[31m.\u001b[0m             \u001b[34m.\u001b[0m\n",
      "\u001b[34m-\u001b[0m             \u001b[31m-\u001b[0m              \u001b[34m-\u001b[0m             \u001b[34m-\u001b[0m               \u001b[34m-\u001b[0m             \u001b[31m-\u001b[0m\n",
      "\u001b[34mIt\u001b[0m            \u001b[31mIt\u001b[0m             \u001b[31mIt\u001b[0m            \u001b[31mIt\u001b[0m              \u001b[34mIt\u001b[0m            \u001b[31mIt\u001b[0m\n",
      "\u001b[34mis\u001b[0m            \u001b[31mis\u001b[0m             \u001b[31mis\u001b[0m            \u001b[31mis\u001b[0m              \u001b[34mis\u001b[0m            \u001b[31mis\u001b[0m\n",
      "\u001b[34ma\u001b[0m             \u001b[31ma\u001b[0m              \u001b[31ma\u001b[0m             \u001b[31ma\u001b[0m               \u001b[34ma\u001b[0m             \u001b[31ma\u001b[0m\n",
      "\u001b[34msensible\u001b[0m      \u001b[31msensible\u001b[0m       \u001b[31msensible\u001b[0m      \u001b[31msensible\u001b[0m        \u001b[34msensible\u001b[0m      \u001b[31msensible\u001b[0m\n",
      "\u001b[34midea\u001b[0m          \u001b[31midea\u001b[0m           \u001b[31midea\u001b[0m          \u001b[31midea\u001b[0m            \u001b[34midea\u001b[0m          \u001b[31midea\u001b[0m\n",
      "\u001b[34mto\u001b[0m            \u001b[31mto\u001b[0m             \u001b[31mto\u001b[0m            \u001b[31mto\u001b[0m              \u001b[34mto\u001b[0m            \u001b[31mto\u001b[0m\n",
      "\u001b[34mtreat\u001b[0m         \u001b[31mtreat\u001b[0m          \u001b[31mtreat\u001b[0m         \u001b[31mtreat\u001b[0m           \u001b[34mtreat\u001b[0m         \u001b[31mtreat\u001b[0m\n",
      "\u001b[34mthe\u001b[0m           \u001b[31mthe\u001b[0m            \u001b[31mthe\u001b[0m           \u001b[31mthe\u001b[0m             \u001b[34mthe\u001b[0m           \u001b[31mthe\u001b[0m\n",
      "\u001b[34mMI\u001b[0m            \u001b[31mMI\u001b[0m             \u001b[31mMI\u001b[0m            \u001b[31mMI\u001b[0m              \u001b[34mMI\u001b[0m            \u001b[31mMI\u001b[0m\n",
      "\u001b[34mterms\u001b[0m         \u001b[31mterms\u001b[0m          \u001b[31mterms\u001b[0m         \u001b[31mterms\u001b[0m           \u001b[34mterms\u001b[0m         \u001b[31mterms\u001b[0m\n",
      "\u001b[34mof\u001b[0m            \u001b[31mof\u001b[0m             \u001b[31mof\u001b[0m            \u001b[31mof\u001b[0m              \u001b[34mof\u001b[0m            \u001b[31mof\u001b[0m\n",
      "\u001b[34mthe\u001b[0m           \u001b[31mthe\u001b[0m            \u001b[31mthe\u001b[0m           \u001b[31mthe\u001b[0m             \u001b[34mthe\u001b[0m           \u001b[31mthe\u001b[0m\n",
      "\u001b[34mdiscrete\u001b[0m      \u001b[31mdiscrete\u001b[0m       \u001b[31mdiscrete\u001b[0m      \u001b[31mdiscrete\u001b[0m        \u001b[34mdiscrete\u001b[0m      \u001b[31mdiscrete\u001b[0m\n",
      "\u001b[34mlatents\u001b[0m       \u001b[31mlatents\u001b[0m        \u001b[31mlatents\u001b[0m       \u001b[31mlatents\u001b[0m         \u001b[34mlatents\u001b[0m       \u001b[31mlatents\u001b[0m\n",
      "\u001b[34mdifferently\u001b[0m   \u001b[31mdifferently\u001b[0m    \u001b[31mdifferently\u001b[0m   \u001b[31mdifferently\u001b[0m     \u001b[34mdifferently\u001b[0m   \u001b[31mdifferently\u001b[0m\n",
      "\u001b[34mto\u001b[0m            \u001b[31mto\u001b[0m             \u001b[31mto\u001b[0m            \u001b[31mto\u001b[0m              \u001b[34mto\u001b[0m            \u001b[31mto\u001b[0m\n",
      "\u001b[34mthe\u001b[0m           \u001b[31mthe\u001b[0m            \u001b[31mthe\u001b[0m           \u001b[31mthe\u001b[0m             \u001b[34mthe\u001b[0m           \u001b[31mthe\u001b[0m\n",
      "\u001b[34mcontinuous\u001b[0m    \u001b[31mcontinuous\u001b[0m     \u001b[31mcontinuous\u001b[0m    \u001b[31mcontinuous\u001b[0m      \u001b[34mcontinuous\u001b[0m    \u001b[31mcontinuous\u001b[0m\n",
      "\u001b[34mlatents\u001b[0m       \u001b[31mlatents\u001b[0m        \u001b[31mlatents\u001b[0m       \u001b[31mlatents\u001b[0m         \u001b[34mlatents\u001b[0m       \u001b[31mlatents\u001b[0m\n",
      "\u001b[34m-\u001b[0m             \u001b[34m-\u001b[0m              \u001b[31m-\u001b[0m             \u001b[34m-\u001b[0m               \u001b[34m-\u001b[0m             \u001b[34m-\u001b[0m\n",
      "\u001b[34mThe\u001b[0m           \u001b[34mThe\u001b[0m            \u001b[34mThe\u001b[0m           \u001b[31mThe\u001b[0m             \u001b[34mThe\u001b[0m           \u001b[34mThe\u001b[0m\n",
      "\u001b[34mmathematical\u001b[0m  \u001b[34mmathematical\u001b[0m   \u001b[34mmathematical\u001b[0m  \u001b[31mmathematical\u001b[0m    \u001b[34mmathematical\u001b[0m  \u001b[34mmathematical\u001b[0m\n",
      "\u001b[34mand\u001b[0m           \u001b[34mand\u001b[0m            \u001b[34mand\u001b[0m           \u001b[31mand\u001b[0m             \u001b[34mand\u001b[0m           \u001b[34mand\u001b[0m\n",
      "\u001b[34mquantitative\u001b[0m  \u001b[34mquantitative\u001b[0m   \u001b[34mquantitative\u001b[0m  \u001b[31mquantitative\u001b[0m    \u001b[34mquantitative\u001b[0m  \u001b[34mquantitative\u001b[0m\n",
      "\u001b[34manalysis\u001b[0m      \u001b[34manalysis\u001b[0m       \u001b[34manalysis\u001b[0m      \u001b[31manalysis\u001b[0m        \u001b[34manalysis\u001b[0m      \u001b[34manalysis\u001b[0m\n",
      "\u001b[34mof\u001b[0m            \u001b[34mof\u001b[0m             \u001b[34mof\u001b[0m            \u001b[31mof\u001b[0m              \u001b[34mof\u001b[0m            \u001b[34mof\u001b[0m\n",
      "\u001b[34mMI\u001b[0m            \u001b[34mMI\u001b[0m             \u001b[34mMI\u001b[0m            \u001b[31mMI\u001b[0m              \u001b[34mMI\u001b[0m            \u001b[34mMI\u001b[0m\n",
      "\u001b[34mand\u001b[0m           \u001b[34mand\u001b[0m            \u001b[34mand\u001b[0m           \u001b[31mand\u001b[0m             \u001b[34mand\u001b[0m           \u001b[34mand\u001b[0m\n",
      "\u001b[34mits\u001b[0m           \u001b[34mits\u001b[0m            \u001b[34mits\u001b[0m           \u001b[31mits\u001b[0m             \u001b[34mits\u001b[0m           \u001b[34mits\u001b[0m\n",
      "\u001b[34mrelation\u001b[0m      \u001b[34mrelation\u001b[0m       \u001b[34mrelation\u001b[0m      \u001b[31mrelation\u001b[0m        \u001b[34mrelation\u001b[0m      \u001b[34mrelation\u001b[0m\n",
      "\u001b[34mto\u001b[0m            \u001b[34mto\u001b[0m             \u001b[34mto\u001b[0m            \u001b[31mto\u001b[0m              \u001b[34mto\u001b[0m            \u001b[34mto\u001b[0m\n",
      "\u001b[34mdecoder\u001b[0m       \u001b[34mdecoder\u001b[0m        \u001b[34mdecoder\u001b[0m       \u001b[31mdecoder\u001b[0m         \u001b[34mdecoder\u001b[0m       \u001b[34mdecoder\u001b[0m\n",
      "\u001b[34mmeans\u001b[0m         \u001b[34mmeans\u001b[0m          \u001b[34mmeans\u001b[0m         \u001b[31mmeans\u001b[0m           \u001b[34mmeans\u001b[0m         \u001b[34mmeans\u001b[0m\n",
      "\u001b[34mand\u001b[0m           \u001b[34mand\u001b[0m            \u001b[34mand\u001b[0m           \u001b[31mand\u001b[0m             \u001b[34mand\u001b[0m           \u001b[34mand\u001b[0m\n",
      "\u001b[34mvariances\u001b[0m     \u001b[34mvariances\u001b[0m      \u001b[34mvariances\u001b[0m     \u001b[31mvariances\u001b[0m       \u001b[34mvariances\u001b[0m     \u001b[34mvariances\u001b[0m\n",
      "\u001b[34mare\u001b[0m           \u001b[34mare\u001b[0m            \u001b[34mare\u001b[0m           \u001b[31mare\u001b[0m             \u001b[34mare\u001b[0m           \u001b[34mare\u001b[0m\n",
      "\u001b[34minformative\u001b[0m   \u001b[34minformative\u001b[0m    \u001b[34minformative\u001b[0m   \u001b[31minformative\u001b[0m     \u001b[34minformative\u001b[0m   \u001b[34minformative\u001b[0m\n",
      "\u001b[34m.\u001b[0m             \u001b[34m.\u001b[0m              \u001b[34m.\u001b[0m             \u001b[31m.\u001b[0m               \u001b[34m.\u001b[0m             \u001b[34m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "text2 = \"Pros:\\n- The derivation of the loss shows a nice link between Mutual information and total correlation in the latents.\\n- It is a sensible idea to treat the MI terms of the discrete latents differently to the continuous latents\\n- The mathematical and quantitative analysis of MI and its relation to decoder means and variances are informative.\"\n",
    "print(make_table(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "progressive-expression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyliNl09h7\n",
      "{\"text\": \"Summary:\\nThis paper presents a research platform with a simulated human (a.k.a bot) in the loop for learning to execute language instructions in which language has compositional structures. The language introduced in this paper can be used to instruct an agent to go to objects, pick up objects, open doors, and put objects next to other objects. MiniGrid is used to build the environments used for this platform. In addition to introducing the platform, they evaluate the difficulty of each level by training an imitation learning baseline using one million demonstration episodes for each level and report results. Moreover, the reported results contain data efficiencies for imitation learning and reinforcement learning based approaches to solving BabyAI levels. \\n\\nA platform like this can be very useful to expedite research in language learning, machine learning, etc. In my view, work like this should be highly encouraged by this conference and alike.  \\n\\nComments:\\n1.  There are following papers should be cited as they are very related to this paper:\\n    a) Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments\\n        https://arxiv.org/abs/1711.07280 \\n    b) AI2-THOR: An Interactive 3D Environment for Visual AI\\n         https://arxiv.org/abs/1712.05474 \\n2. Paper is well-written and easy to follow. The only part which needs an improvement is section 3.4 as the text is a bit confusing.\\n3. Heuristic expert, simulated human, human, and bot are exchangeably used in the text. It is better to pick one of these to avoid any confusion in the text. In general, it is not clear to why 'a human in the loop' is chosen, isn't just a program/bot that has is engineered using knowledge of the tasks?\\n4. In Table 5, in GoToObjMaze row, data efficiency for \\\"With Pretraining\\\" is greater than \\\"Without Pretraining\\\", is this a typo? if not, why this is the case?\\n5. One useful baseline which can be added to this paper is task-oriented language grounding. This task will be a better measure than current baselines, especially for RL case. Authors can check out the following paper:\\nGated-Attention Architectures for Task-Oriented Language Grounding\\nhttps://arxiv.org/abs/1706.07230\\nThe code is available for this paper. \\n\\nQuestion:\\nWhen this platform will be available for public? \", \"sentences\": [{\"start_index\": 0, \"end_index\": 8, \"suffix\": \"\\n\"}, {\"start_index\": 9, \"end_index\": 189, \"suffix\": \"\"}, {\"start_index\": 190, \"end_index\": 346, \"suffix\": \"\"}, {\"start_index\": 347, \"end_index\": 413, \"suffix\": \"\"}, {\"start_index\": 414, \"end_index\": 616, \"suffix\": \"\"}, {\"start_index\": 617, \"end_index\": 766, \"suffix\": \"\\n\\n\"}, {\"start_index\": 769, \"end_index\": 874, \"suffix\": \"\"}, {\"start_index\": 875, \"end_index\": 959, \"suffix\": \"\\n\\n\"}, {\"start_index\": 963, \"end_index\": 972, \"suffix\": \"\\n\"}, {\"start_index\": 973, \"end_index\": 975, \"suffix\": \"\"}, {\"start_index\": 977, \"end_index\": 1059, \"suffix\": \"\\n\"}, {\"start_index\": 1064, \"end_index\": 1174, \"suffix\": \"\\n\"}, {\"start_index\": 1183, \"end_index\": 1215, \"suffix\": \"\\n\"}, {\"start_index\": 1221, \"end_index\": 1277, \"suffix\": \"\\n\"}, {\"start_index\": 1287, \"end_index\": 1319, \"suffix\": \"\"}, {\"start_index\": 1312, \"end_index\": 1314, \"suffix\": \"\\n\"}, {\"start_index\": 1324, \"end_index\": 1365, \"suffix\": \"\"}, {\"start_index\": 1366, \"end_index\": 1453, \"suffix\": \"\"}, {\"start_index\": 1418, \"end_index\": 1420, \"suffix\": \"\\n\"}, {\"start_index\": 1457, \"end_index\": 1541, \"suffix\": \"\"}, {\"start_index\": 1542, \"end_index\": 1611, \"suffix\": \"\"}, {\"start_index\": 1612, \"end_index\": 1757, \"suffix\": \"\\n\"}, {\"start_index\": 1758, \"end_index\": 1760, \"suffix\": \"\"}, {\"start_index\": 1761, \"end_index\": 1886, \"suffix\": \"\"}, {\"start_index\": 1887, \"end_index\": 1916, \"suffix\": \"\\n\"}, {\"start_index\": 1917, \"end_index\": 1919, \"suffix\": \"\"}, {\"start_index\": 1920, \"end_index\": 2009, \"suffix\": \"\"}, {\"start_index\": 2010, \"end_index\": 2092, \"suffix\": \"\"}, {\"start_index\": 2093, \"end_index\": 2135, \"suffix\": \"\\n\"}, {\"start_index\": 2136, \"end_index\": 2202, \"suffix\": \"\\n\"}, {\"start_index\": 2203, \"end_index\": 2235, \"suffix\": \"\\n\"}, {\"start_index\": 2236, \"end_index\": 2273, \"suffix\": \"\\n\\n\"}, {\"start_index\": 2276, \"end_index\": 2285, \"suffix\": \"\\n\"}, {\"start_index\": 2286, \"end_index\": 2334, \"suffix\": \"\"}]}\n",
      "Summary:\n",
      "This paper presents a research platform with a simulated human (a.k.a bot) in the loop for learning to execute language instructions in which language has compositional structures.The language introduced in this paper can be used to instruct an agent to go to objects, pick up objects, open doors, and put objects next to other objects.MiniGrid is used to build the environments used for this platform.In addition to introducing the platform, they evaluate the difficulty of each level by training an imitation learning baseline using one million demonstration episodes for each level and report results.Moreover, the reported results contain data efficiencies for imitation learning and reinforcement learning based approaches to solving BabyAI levels.\n",
      "\n",
      "A platform like this can be very useful to expedite research in language learning, machine learning, etc.In my view, work like this should be highly encouraged by this conference and alike.\n",
      "\n",
      "Comments:\n",
      "1.There are following papers should be cited as they are very related to this paper:\n",
      "a) Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments\n",
      "https://arxiv.org/abs/1711.07280\n",
      "b) AI2-THOR: An Interactive 3D Environment for Visual AI\n",
      "https://arxiv.org/abs/1712.054742.\n",
      "Paper is well-written and easy to follow.The only part which needs an improvement is section 3.4 as the text is a bit confusing.3.\n",
      "Heuristic expert, simulated human, human, and bot are exchangeably used in the text.It is better to pick one of these to avoid any confusion in the text.In general, it is not clear to why 'a human in the loop' is chosen, isn't just a program/bot that has is engineered using knowledge of the tasks?\n",
      "4.In Table 5, in GoToObjMaze row, data efficiency for \"With Pretraining\" is greater than \"Without Pretraining\", is this a typo?if not, why this is the case?\n",
      "5.One useful baseline which can be added to this paper is task-oriented language grounding.This task will be a better measure than current baselines, especially for RL case.Authors can check out the following paper:\n",
      "Gated-Attention Architectures for Task-Oriented Language Grounding\n",
      "https://arxiv.org/abs/1706.07230\n",
      "The code is available for this paper.\n",
      "\n",
      "Question:\n",
      "When this platform will be available for public?\n",
      "================================================================================\n",
      "SkebaWdinm\n",
      "{\"text\": \"This paper focuses on grounded language learning with a human in the loop, in the sense where the language is synthetic, the environment is a 2D grid world, and the human is a simulated human teacher implemented using heuristics. This setup is dubbed the BabyAI platform, and includes curriculum learning over 19 levels of increasing difficulty.  \\n\\nOverall, the BabyAI platform is conceptually similar to numerous previous works that seek to learn grounded language in simulation environments. These efforts differ along various axes, for example visual realism, 2D vs 3D, partially vs. fully observed, different tasks, world-state manipulation or not, etc. The main original aspect of the BabyAI platform is the simulated human-teacher. \\n\\nStrengths\\n- Learning with a human in the loop is an extremely important problem to study, although currently efforts are hampered by cost, lack or reproducibility, and the sample inefficiency of existing learning methods. This paper addresses all three of these issues, albeit by removing the human and natural language. This is simultaneously the greatest weakness of this approach. The contribution of this paper therefore rests on the quality/interestingness/utility of the provided synthetic language and the synthetic teacher.\\n- Fortunately, the synthetic language does exhibit interesting compositional properties, it is readily extensible, it has the appealing property that it can be readily interpreted as a subset of english, and it is accompanied by a verifier to check if the specified actions were completed. \\n\\nWeaknesses\\n- If the ultimate goal is learning with a human in the loop, the usefulness of the synthetic teacher is not clear, particularly as it is apparently easier to imitate from an RL trained agent than the teacher. The explanation 'This can explained by the fact that the RL expert has the same neural network architecture as the learner' does no seem obvious to me. \\n- Regarding the human in the loop, since this is aspirational and not an aspect of the paper, the title of the paper does not seem reflective of its content (even with the 'First steps' qualifier). \\n- If the main unique aspect is the simulated human-teacher, it is not clear why it is necessary to create a new environment, rather than re-using an existing environment. The effect of this is to limit comparisons with recent work and an increasing fragmentation of research across tasks that are related but can\\u2019t be compared.\\n\\nSummary:\\nThis paper represents an important direction, in that it provides a testbed for studying the sample efficiency of grounded language learning in a simplified (yet still challenging and compositional) environment. I believe the environment and the provided synthetic language and verifier will prove useful to the community, and despite some reservations about the title and the simulated human-teacher, I recommend acceptance.\", \"sentences\": [{\"start_index\": 0, \"end_index\": 229, \"suffix\": \"\"}, {\"start_index\": 230, \"end_index\": 345, \"suffix\": \"\\n\\n\"}, {\"start_index\": 349, \"end_index\": 493, \"suffix\": \"\"}, {\"start_index\": 494, \"end_index\": 657, \"suffix\": \"\"}, {\"start_index\": 658, \"end_index\": 737, \"suffix\": \"\\n\\n\"}, {\"start_index\": 740, \"end_index\": 749, \"suffix\": \"\\n\"}, {\"start_index\": 750, \"end_index\": 961, \"suffix\": \"\"}, {\"start_index\": 962, \"end_index\": 1060, \"suffix\": \"\"}, {\"start_index\": 1061, \"end_index\": 1123, \"suffix\": \"\"}, {\"start_index\": 1124, \"end_index\": 1271, \"suffix\": \"\\n\"}, {\"start_index\": 1272, \"end_index\": 1561, \"suffix\": \"\\n\\n\"}, {\"start_index\": 1564, \"end_index\": 1574, \"suffix\": \"\\n\"}, {\"start_index\": 1575, \"end_index\": 1783, \"suffix\": \"\"}, {\"start_index\": 1784, \"end_index\": 1935, \"suffix\": \"\\n\"}, {\"start_index\": 1937, \"end_index\": 2134, \"suffix\": \"\\n\"}, {\"start_index\": 2136, \"end_index\": 2306, \"suffix\": \"\"}, {\"start_index\": 2307, \"end_index\": 2463, \"suffix\": \"\\n\\n\"}, {\"start_index\": 2465, \"end_index\": 2473, \"suffix\": \"\\n\"}, {\"start_index\": 2474, \"end_index\": 2685, \"suffix\": \"\"}, {\"start_index\": 2686, \"end_index\": 2899, \"suffix\": \"\"}]}\n",
      "This paper focuses on grounded language learning with a human in the loop, in the sense where the language is synthetic, the environment is a 2D grid world, and the human is a simulated human teacher implemented using heuristics.This setup is dubbed the BabyAI platform, and includes curriculum learning over 19 levels of increasing difficulty.\n",
      "\n",
      "Overall, the BabyAI platform is conceptually similar to numerous previous works that seek to learn grounded language in simulation environments.These efforts differ along various axes, for example visual realism, 2D vs 3D, partially vs. fully observed, different tasks, world-state manipulation or not, etc.The main original aspect of the BabyAI platform is the simulated human-teacher.\n",
      "\n",
      "Strengths\n",
      "- Learning with a human in the loop is an extremely important problem to study, although currently efforts are hampered by cost, lack or reproducibility, and the sample inefficiency of existing learning methods.This paper addresses all three of these issues, albeit by removing the human and natural language.This is simultaneously the greatest weakness of this approach.The contribution of this paper therefore rests on the quality/interestingness/utility of the provided synthetic language and the synthetic teacher.\n",
      "- Fortunately, the synthetic language does exhibit interesting compositional properties, it is readily extensible, it has the appealing property that it can be readily interpreted as a subset of english, and it is accompanied by a verifier to check if the specified actions were completed.\n",
      "\n",
      "Weaknesses\n",
      "- If the ultimate goal is learning with a human in the loop, the usefulness of the synthetic teacher is not clear, particularly as it is apparently easier to imitate from an RL trained agent than the teacher.The explanation 'This can explained by the fact that the RL expert has the same neural network architecture as the learner' does no seem obvious to me.\n",
      "- Regarding the human in the loop, since this is aspirational and not an aspect of the paper, the title of the paper does not seem reflective of its content (even with the 'First steps' qualifier).\n",
      "- If the main unique aspect is the simulated human-teacher, it is not clear why it is necessary to create a new environment, rather than re-using an existing environment.The effect of this is to limit comparisons with recent work and an increasing fragmentation of research across tasks that are related but can’t be compared.\n",
      "\n",
      "Summary:\n",
      "This paper represents an important direction, in that it provides a testbed for studying the sample efficiency of grounded language learning in a simplified (yet still challenging and compositional) environment.I believe the environment and the provided synthetic language and verifier will prove useful to the community, and despite some reservations about the title and the simulated human-teacher, I recommend acceptance.\n",
      "================================================================================\n",
      "r1eeyarz3m\n",
      "{\"text\": \"Summary\\n\\nThe authors introduce BabyAI, a platform with the aim to study grounded language learning with a human in the loop. The platform includes a *simulated* human expert (bot) that teaches a neural learner. The current domain used in a 2D gridworld and the synthetic instructions require the agent to navigate the world (including unlocking doors) and move objects to specified locations. They also introduce \\\"Baby Language\\\" to give instructions to the agent as well as to automatically verify their execution.\\n\\nThe paper includes a detailed description of the minigrid env with the included tasks and instruction language set. \\n\\nAuthors trained small and large LSTM models on the tasks on a variety of standard learning approaches, using pure exploration (RL) and imitation from a synthetic bot (IL). They show IL is much more data efficient than RL in this domain as well. Also, a curriculum approach is evaluated (pre-train on task 1-N, then train on task N+1).  \\n\\nPro\\n- Human-in-the-loop research is an exciting direction.\\n- The language instruction set is a starting point for high-level human instructions. \\n\\nCon\\n- It is still unclear how to effectively learn with human-in-the-loop. The authors don't actually evaluate \\n1) how well the bot imitates a human, or \\n2) how an actual human would interact and speed up learning. \\nAll experiments are done with standard learning approaches with a synthetic bot. \\n- The authors assume that human feedback comes as instructions or demonstrations. These are not the only forms of feedback possible (e.g., preferences). (Does the platform easily support those?)\\n\\nReproducibility\\n- Open-sourcing the platform is a good contribution to the community.\\n\", \"sentences\": [{\"start_index\": 0, \"end_index\": 7, \"suffix\": \"\\n\\n\"}, {\"start_index\": 9, \"end_index\": 124, \"suffix\": \"\"}, {\"start_index\": 125, \"end_index\": 210, \"suffix\": \"\"}, {\"start_index\": 211, \"end_index\": 392, \"suffix\": \"\"}, {\"start_index\": 393, \"end_index\": 514, \"suffix\": \"\\n\\n\"}, {\"start_index\": 516, \"end_index\": 631, \"suffix\": \"\\n\\n\"}, {\"start_index\": 634, \"end_index\": 805, \"suffix\": \"\"}, {\"start_index\": 806, \"end_index\": 878, \"suffix\": \"\"}, {\"start_index\": 879, \"end_index\": 968, \"suffix\": \"\\n\\n\"}, {\"start_index\": 972, \"end_index\": 975, \"suffix\": \"\\n\"}, {\"start_index\": 976, \"end_index\": 1030, \"suffix\": \"\\n\"}, {\"start_index\": 1031, \"end_index\": 1116, \"suffix\": \"\\n\\n\"}, {\"start_index\": 1119, \"end_index\": 1122, \"suffix\": \"\\n\"}, {\"start_index\": 1123, \"end_index\": 1193, \"suffix\": \"\"}, {\"start_index\": 1194, \"end_index\": 1229, \"suffix\": \"\\n\"}, {\"start_index\": 1231, \"end_index\": 1271, \"suffix\": \"\\n\"}, {\"start_index\": 1273, \"end_index\": 1333, \"suffix\": \"\\n\"}, {\"start_index\": 1335, \"end_index\": 1415, \"suffix\": \"\\n\"}, {\"start_index\": 1417, \"end_index\": 1498, \"suffix\": \"\"}, {\"start_index\": 1499, \"end_index\": 1571, \"suffix\": \"\"}, {\"start_index\": 1571, \"end_index\": 1611, \"suffix\": \"\\n\\n\"}, {\"start_index\": 1613, \"end_index\": 1628, \"suffix\": \"\\n\"}, {\"start_index\": 1629, \"end_index\": 1698, \"suffix\": \"\"}]}\n",
      "Summary\n",
      "\n",
      "The authors introduce BabyAI, a platform with the aim to study grounded language learning with a human in the loop.The platform includes a *simulated* human expert (bot) that teaches a neural learner.The current domain used in a 2D gridworld and the synthetic instructions require the agent to navigate the world (including unlocking doors) and move objects to specified locations.They also introduce \"Baby Language\" to give instructions to the agent as well as to automatically verify their execution.\n",
      "\n",
      "The paper includes a detailed description of the minigrid env with the included tasks and instruction language set.\n",
      "\n",
      "Authors trained small and large LSTM models on the tasks on a variety of standard learning approaches, using pure exploration (RL) and imitation from a synthetic bot (IL).They show IL is much more data efficient than RL in this domain as well.Also, a curriculum approach is evaluated (pre-train on task 1-N, then train on task N+1).\n",
      "\n",
      "Pro\n",
      "- Human-in-the-loop research is an exciting direction.\n",
      "- The language instruction set is a starting point for high-level human instructions.\n",
      "\n",
      "Con\n",
      "- It is still unclear how to effectively learn with human-in-the-loop.The authors don't actually evaluate\n",
      "1) how well the bot imitates a human, or\n",
      "2) how an actual human would interact and speed up learning.\n",
      "All experiments are done with standard learning approaches with a synthetic bot.\n",
      "- The authors assume that human feedback comes as instructions or demonstrations.These are not the only forms of feedback possible (e.g., preferences). (Does the platform easily support those?)\n",
      "\n",
      "Reproducibility\n",
      "- Open-sourcing the platform is a good contribution to the community.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import openreview_lib as orl\n",
    "import openreview\n",
    "import collections\n",
    "import json\n",
    "\n",
    "from spacy.lang.en import English\n",
    "client = openreview.Client(baseurl='https://api.openreview.net')\n",
    "TRIAL_FORUM = \"rJeXCo0cYX\"\n",
    "notes = client.get_notes(forum=TRIAL_FORUM)\n",
    "note_map = {note.id: note for note in notes} \n",
    "pairs = orl.get_forum_pairs(TRIAL_FORUM, note_map)\n",
    "\n",
    "\n",
    "Sentence = collections.namedtuple(\"Sentence\", \"start_index end_index suffix\")\n",
    "Comment = collections.namedtuple(\"Comment\", \"text sentences\")\n",
    "\n",
    "def make_sentence_dict(start, end, suffix):\n",
    "    return Sentence(start, end, suffix)._asdict()\n",
    "\n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "def my_sentencize(pipeline, text):\n",
    "    sentence_texts = []\n",
    "    sentence_indices = []\n",
    "    for chunk in text.split(\"\\n\"):\n",
    "        doc = pipeline(chunk)\n",
    "        for sent in doc.sents:\n",
    "            sentence_text = sent.text.strip()\n",
    "            if not sentence_text:\n",
    "                continue\n",
    "            index = text.find(sentence_text)\n",
    "            if sentence_indices:\n",
    "                assert index > sentence_indices[-1][0]\n",
    "            sentence_texts.append(sentence_text)\n",
    "            sentence_indices.append((index, index + len(sentence_text)))\n",
    "\n",
    "    assert len(sentence_texts) == len(sentence_indices)\n",
    "\n",
    "    final_sentences = []\n",
    "    for i in range(len(sentence_texts) - 1):\n",
    "        start, end = sentence_indices[i]\n",
    "        sentence_text = sentence_texts[i]\n",
    "        next_sentence_start = sentence_indices[i+1][0]\n",
    "        suffix = \"\\n\" * text[end:next_sentence_start].count(\"\\n\")\n",
    "        assert sentence_text == text[start:end]\n",
    "        final_sentences.append(make_sentence_dict(start, end, suffix))\n",
    "\n",
    "    final_start, final_end = sentence_indices[-1]\n",
    "    final_sentences.append(make_sentence_dict(final_start, final_end, \"\"))\n",
    "    \n",
    "    return Comment(text, final_sentences)._asdict()\n",
    "\n",
    "\n",
    "for pair in pairs:\n",
    "    print(pair.review_sid)\n",
    "    trial_review = note_map[pair.review_sid].content[\"review\"]\n",
    "    final_sentences = my_sentencize(nlp, trial_review)\n",
    "    print(json.dumps(final_sentences))\n",
    "    for sent in final_sentences[\"sentences\"]:\n",
    "       print(\n",
    "           final_sentences[\"text\"][sent[\"start_index\"]:sent[\"end_index\"]]+sent[\"suffix\"], end=\"\")\n",
    "    print()\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-accreditation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-pencil",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
