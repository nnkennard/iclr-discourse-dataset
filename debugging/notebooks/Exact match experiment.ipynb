{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rubber-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "PAIR_FILE = \"review_rebuttal_pair_dataset_debug/traindev_train.json\"\n",
    "\n",
    "with open(PAIR_FILE, 'r') as f:\n",
    "    pair_obj = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cardiac-costa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cdifflib\n",
      "  Downloading cdifflib-1.2.5.tar.gz (7.7 kB)\n",
      "Using legacy 'setup.py install' for cdifflib, since package 'wheel' is not installed.\n",
      "Installing collected packages: cdifflib\n",
      "    Running setup.py install for cdifflib ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed cdifflib-1.2.5\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Users/nnayak/git_repos/iclr-discourse-dataset/iddve/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install cdifflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bibliographic-arrangement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "In this paper, we propose the idea of guidance itself and show that it is imposing a desired semantics on the latent space without having labeled data.\n",
      "[ and show that it is ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "[Differentiable Guidance]  The transformations need to be differentiable in order to backpropagate the gradients into our generator.\n",
      "[ to backpropagate the gradient]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "[Gaussian Prior on Latents] In our new experiments, we used uniform distributions to model the generative factors.\n",
      "[ the generative factors]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "[Similar Latent Factors] We now use an adaptive margin that depends on the distance between two latent samples.\n",
      "[ the distance between ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "We also updated our “Probabilistic Interpretation” section with analysis on how the contrastive loss helps us to learn a disentangled representation.\n",
      "[ disentangled representation]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Q1: How to select the intermediate temperature alpha.\n",
      "\n",
      "[ the intermediate temperature ]\n",
      "\n",
      "A1: A good intermediate temperature value can be selected by cross-validation.\n",
      "[ intermediate temperature ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Q2: How \"heated-up\" strategy produces well generalized feature?\n",
      "\n",
      "[ \"heated-up\" strategy produces well generalized feature]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Q3: How different alpha values change the ratio of #incorrect samples with #total samples and #boundary samples with #total samples?\n",
      "\n",
      "[e the ratio of #incorrect]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "This may help improve the learning speed.\n",
      "[ improve the learning speed]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "This terminology and setting have been widely used in recent years (Hoffer & Ailon, 2015, Harwood et al.,\n",
      "[ have been widely used ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Q3: The correlation between the final performance and temperature setting is not evaluated.\n",
      "\n",
      "[he correlation between the final performance and t]\n",
      "\n",
      "A3: The correlation between the final performance and temperature is evaluated in Table 3.\n",
      "[he correlation between the final performance and t]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Q4: The side-effect on the learning rate setting is not analyzed.\n",
      "\n",
      "[he side-effect on the learning rate setting ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "In the table, only the second column is the result of softmax without normalization.\n",
      "[ softmax without normalization.]\n",
      "\n",
      "All other results are with normalization applied to both the feature and the weight which is the same setting as HBN.\n",
      "[ with normalization ]\n",
      "\n",
      "..\n",
      "\n",
      "Q3: Explain why the temperature T should be increased in the training and better explain Fig.\n",
      "[ why the temperature T should be increased in the training]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "It helps to get more discriminative feature representation.\n",
      "[ feature representation]\n",
      "\n",
      "We’ve added Appendix F to explain this and provided experiments results of training the embedding without normalization.\n",
      "\n",
      "\n",
      "[ without normalization.\n",
      "]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "1) * There is not enough quantitative comparison of the quality of disentanglement across the different methods.\n",
      "\n",
      "\n",
      "[ There is not enough quantitative comparison of the quality of disentanglement across the different methods.]\n",
      "\n",
      "We fully agree that a quantitative comparison of the disentanglement quality regrading both continuous and discrete representations significantly improves the paper.\n",
      "[ a quantitative comparison of the disentangle]\n",
      "\n",
      "We provide a quantitative comparison in terms of the disentanglement quality vs. reconstruction error trade-off on dSprites.\n",
      "[ a quantitative comparison ]\n",
      "\n",
      "..\n",
      "\n",
      "We found that, IMAE consistently performs better in terms of achieving better disentanglement quality vs. reconstruction error trade-off over a wide range of beta, gamma values.\n",
      "[ reconstruction error]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "We suspect that simply pushing the upper bound the mutual information towards a target value does not explicitly encourage disentanglement across the representation factors.\n",
      "\n",
      "\n",
      "\n",
      "[ disentanglement across the ]\n",
      "\n",
      "2)*  Shouldn’t you be doing a hyperparameter sweep for each model and choose the best value of hyperparameters for each?\n",
      "\n",
      "\n",
      "[Shouldn’t you be doing a hyperparameter sweep for each model and choose the best value of hyperparameters for each?]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "3)* Looking at Appendix D, it seems like VAT makes a big difference in terms of I(y;y_true), so I’m guessing it will also have a big impact on the accuracy.\n",
      "[Looking at Appendix D, it seems like VAT makes a big difference in terms of I(y;y_true), so I’m guessing it will also have a big impact on the accuracy.]\n",
      "\n",
      "Thus JointVAE + VAT might beat IMAE in terms of accuracy as well, at which point it will be hard to argue that IMAE is superior in learning the discrete factor.\n",
      "\n",
      "\n",
      "[Thus JointVAE + VAT might beat IMAE in terms of accuracy as well, at which point it will be hard to argue that IMAE is superior in learning the discrete factor.\n",
      "]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "4)* In the first paragraph of Section 4, the authors claim results on CelebA, but these are missing from the paper.\n",
      "[ In the first paragraph of Section 4, the authors claim results on CelebA, but these are missing from the paper.]\n",
      "\n",
      "Testing the approach on datasets more complex than (Fashion)Mnist would have been desirable.\n",
      "\n",
      "\n",
      "[Testing the approach on datasets more complex than (Fashion)Mnist would have been desirable.\n",
      "]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "5)* There aren’t any latent traversals for the discrete latents - this would be a useful visualisation to complement the accuracy plots in Figure 3.\n",
      "\n",
      "\n",
      "[ There aren’t any latent traversals for the discrete latents - this would be a useful visualisation to complement the accuracy plots in Figure 3.\n",
      "\n",
      "]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Hence, jointly optimizing I(x; y,z) and KL can yield informative representations  as well as good posterior approximation quality (both KL divergence and CrossEntropy(p(x|y,z), q(x|y,z)) are small).\n",
      "\n",
      "[ posterior approximation quality (]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "That is the model degenerate to a plain auto-encoder, optimizing (***) is equivalent to simply optimizing CrossEntropy(p(x|y,z), q(x|y,z)) (the reconstruction error).\n",
      "[the reconstruction error]\n",
      "\n",
      "Therefore, by setting the weight larger than 1, we can simultaneously attain good posterior approximation quality and informative representations with desired distributions.\n",
      "\n",
      "\n",
      "[ posterior approximation quality ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "1)*  It seems a little strange to me to incorporate the VAT regularization to the IMAE framework in Section 4.2, as this is not included in the overall objective in Equation (10) and earlier analysis (Proposition 1 and 2).\n",
      "[ It seems a little strange to me to incorporate the VAT regularization to the IMAE framework in Section 4.2, as this is not included in the overall objective in Equation (10) and earlier analysis (Proposition 1 and 2).]\n",
      "\n",
      "Will the conclusions in Proposition 1 and 2 change accordingly due to the inclusion of VAT regularization?\n",
      "\n",
      "\n",
      "[Will the conclusions in Proposition 1 and 2 change accordingly due to the inclusion of VAT regularization?\n",
      "\n",
      "]\n",
      "\n",
      "VAT is proposed to resolve the inherent difficulty of learning interpretable discrete representations using neural network.\n",
      "[discrete representation]\n",
      "\n",
      "..\n",
      "\n",
      "In our experimental results, we found that using VAT are significantly helpful for learning interpretable discrete representations for all methods considered in this paper except betaVAE.\n",
      "[discrete representation]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "2) * The paper states that IMAE has better trade-off among interpretability and decoding quality.\n",
      "[* The paper states that IMAE has better trade-off among interpretability and decoding quality.]\n",
      "\n",
      "But it is still unclear how a user can choose a good trade-off according to different applications.\n",
      "[But it is still unclear how a user can choose a good trade-off according to different applications.]\n",
      "\n",
      "More discussion along this direction would be helpful.\n",
      "\n",
      "\n",
      "[More discussion along this direction would be helpful.\n",
      "\n",
      "]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "3)* I guess the L(y) term in Equation (10) is from Equation (9), but this is not stated explicitly in the paper.\n",
      "\n",
      "\n",
      "[* I guess the L(y) term in Equation (10) is from Equation (9), but this is not stated explicitly in the paper.]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "For each scalar representation factor z_k, we (mathematically) show in section 3.2 that the trivial solution of maximizing I(x, z_k)  can be obtained by severely fragmenting the latent space.\n",
      "[t the trivial solution ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "3) We update the paper by considering more challenging dataset and incorporating more quantitative evaluations regarding the trade-off between interpretability of representations and decoding quality.\n",
      "[ the trade-off between ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "After Eq 3.7: In the appendix of our updated paper, we have specified how these assumptions are satisfied by a logging policy that follows the multinomial logistic model.\n",
      "\n",
      "\n",
      "[ logging policy that ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Clipping Constant: We do not introduce extra clipping constant in our ML-based approach.\n",
      "[a clipping constant ]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "\n",
      "..\n",
      "\n",
      "The POEM algorithm is based on the propensity weight capping approach, which has a clipping constant M.\n",
      "\n",
      "\n",
      "[as a clipping constant M]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Alternative Techniques: In fact, the POEM algorithm is a technique using a clipping constant to ensure no small propensities.\n",
      "[ ensure no small propensities]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Throughout the theoretical analysis, we assume that the parametrization of the logging policy is known.\n",
      "[he theoretical analysis, w]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "The improvements made us rank among prize wining teams in that challenge, which convince us that the ML-based approach did achieve significant improvements in this case.\n",
      "[ improvements in this case.]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“About the use of Reddit: this might not be the best background dataset, as it’s mostly strangers talking to other strangers, presumably causing the baseline to be weak on empathy. “\n",
      "\n",
      "[About the use of Reddit: this might not be the best background dataset, as it’s mostly strangers talking to other strangers, presumably causing the baseline to be weak on empathy.]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "The other one is to look for another background dataset, as you suggest.\n",
      "[ background dataset, as ]\n",
      "\n",
      "..\n",
      "\n",
      "We like your specific suggestion of “Twitter or other social-network type datasets (letting you follow people rather topics)”, and we indeed know of existing datasets from Twitter of a large scale, but they have shortcomings.\n",
      "[Twitter or other social-network type datasets (letting you follow people rather topics)]\n",
      "\n",
      "..\n",
      "\n",
      "Second, existing publicly released datasets are orders of magnitude lower in scale, and the conversations are very short.\n",
      "[, and the conversations ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“ exchanges that are rather cliché and overdone (e.g., Table 1: the label “afraid” yields a situation that is rather spooky and unlikely in the real world, and the conversations themselves are rather cliché and incorporate little details that would make them sound real).”:\n",
      "[ exchanges that are rather cliché and overdone (e.g., Table 1: the label “afraid” yields a situation that is rather spooky and unlikely in the real world, and the conversations themselves are rather cliché and incorporate little details that would make them sound real).]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“existing real-world datasets underrepresent rare emotions (e.g., afraid), but that’s just a reflection of how these emotions are distributed in the real world.”:\n",
      "[existing real-world datasets underrepresent rare emotions (e.g., afraid), but that’s just a reflection of how these emotions are distributed in the real world.]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“but the question the authors do not satisfactorily address is whether their explicit (and I would say sometimes ad-hoc) treatment of empathy (e.g., using emotion classifier, etc.)\n",
      "[but the question the authors do not satisfactorily address is whether their explicit (and I would say sometimes ad-hoc) treatment of empathy (e.g., using emotion classifier, etc.)]\n",
      "\n",
      "is crucially needed to get better empathetic dialogues [...]”: thank you very much for making that point, and making us realize that our experimental results would benefit from disentanglement.\n",
      "[is crucially needed to get better empathetic dialogues]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“More statistics in the table in terms of number of parameters and amount of in- and out-of-domain data used for each experiment would help draw a clearer picture.”\n",
      "[More statistics in the table in terms of number of parameters and amount of in- and out-of-domain data used for each experiment would help draw a clearer picture.]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“doesn’t really attempt to make major technical contribution”: we do not argue to the contrary, and it was definitely not how we had tried to cast our contribution.\n",
      "[doesn’t really attempt to make major technical contribution]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“The conclusions are somewhat fuzzy as there are , and as a result no clear cut recommendations can be made”: thanks for pointing that out -- we have extensively reorganized our paper to make the motivations and results clearer; please also see our response in the general thread.\n",
      "\n",
      "\n",
      "[The conclusions are somewhat fuzzy as there are ]\n",
      "\n",
      "“How is the \"situation description\" supposed to be related to the\n",
      "\n",
      "[How is the \"situation description\" supposed to be related to the\n",
      "]\n",
      "\n",
      "opening sentence of the speaker?\n",
      "[opening sentence of the speaker?]\n",
      "\n",
      "In the examples there seems to be substantial\n",
      "\n",
      "[In the examples there seems to be substantial\n",
      "]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Workers sometimes stuck to the situation description closely, while others were more creative about re-wording things.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[situation description]\n",
      "\n",
      "“this is a very refined set that could get blurred at the boundaries between similar emotions.”:\n",
      "\n",
      "[this is a very refined set that could get blurred at the boundaries between similar emotions.]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Distinction between similar emotions was not as important to us, since our main focus was generating situations to which Listeners could react with empathy, rather than distinguishing between them.\n",
      "[ between similar emotions]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“does everyone interpret the same emotion label the same way”: no, indeed, but the agreement between humans is high enough to get good signal, and this has been quantified -- for example, see Fig 1C in Skerry and Saxe 2015  (reference in the paper) that finds an accuracy of 65% for 20 labels (all part of our set of 32), where chance would be 5%.\n",
      "\n",
      "[does everyone interpret the same emotion label the same way]\n",
      "\n",
      "..\n",
      "\n",
      "“ will such potential ambiguities impact the work?\n",
      "\n",
      "[ will such potential ambiguities impact the work?\n",
      "]\n",
      "\n",
      "One way to learn more about this is to aggregate related emotions to make a coarser set,\n",
      "\n",
      "[One way to learn more about this is to aggregate related emotions to make a coarser set,\n",
      "]\n",
      "\n",
      "and compare the results.” “\n",
      "[and compare the results.]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "As you also mention, “To some extent this is leveraged by the prepending method (with top-K emotion predictions).” --\n",
      "[To some extent this is leveraged by the prepending method (with top-K emotion predictions).]\n",
      "\n",
      "..\n",
      "\n",
      "“on using an existing emotion predictor:  does it predict the same set of emotions\n",
      "\n",
      "[on using an existing emotion predictor:  does it predict the same set of emotions\n",
      "]\n",
      "\n",
      "that you are using in this work?”\n",
      "[that you are using in this work?]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“I think it could have been better organized.”:\n",
      "[I think it could have been better organized.]\n",
      "\n",
      "..\n",
      "\n",
      "““ I would have appreciated a better explanation of the rationale for using BLEU scores.\n",
      "[ I would have appreciated a better explanation of the rationale for using BLEU scores.]\n",
      "\n",
      "I did some online research to understand these Bilingual Evaluation Understudy Scores and while it seems like they measure sentence similarity, it is unclear how they capture ”relevance” at least according to the brief tutorial that I read (https://machinelearningmastery.com/calculate-bleu-score-for-text-python/).”::\n",
      "[I did some online research to understand these Bilingual Evaluation Understudy Scores and while it seems like they measure sentence similarity, it is unclear how they capture ”relevance” at least according to the brief tutorial that I read (https://machinelearningmastery.com/calculate-bleu-score-for-text-python/).]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Individual workers did not have to have conversations about all 32 emotions; instead, coverage of all emotions was ensured by offering more often the emotions that had been selected less overall.\n",
      "[ about all 32 emotions]\n",
      "\n",
      "..\n",
      "\n",
      "As to your specific questions: the median number of conversations per worker was 8, while the average was 61.\n",
      "[ number of conversations ]\n",
      "\n",
      "..\n",
      "\n",
      "To ensure quality, we hand-checked random subsets of conversations by our most-frequent workers.\n",
      "[sets of conversations ]\n",
      "\n",
      "..\n",
      "\n",
      "We have added that information to the crowdsourcing description in the appendix, as well as a larger random sample of conversations from the dataset.\n",
      "\n",
      "\n",
      "[ conversations from the ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“This would imply that some emotional situations were less preferred and potentially more difficult to write about.\n",
      "[This would imply that some emotional situations were less preferred and potentially more difficult to write about.]\n",
      "\n",
      "It would be interesting if this data was presented. “:\n",
      "[It would be interesting if this data was presented.]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“which also seems to be the first utterance in the dialog they will start” / “you state that the dialog model has access to the situation description given by the speaker (also later called the situational prompt) but not the emotion word prompt.” / “\n",
      "[you state that the dialog model has access to the situation description given by the speaker (also later called the situational prompt) but not the emotion word prompt.]\n",
      "\n",
      "Calling these both prompts makes the statement about 24,850 prompts/conversations a bit ambiguous. “:\n",
      "[Calling these both prompts makes the statement about 24,850 prompts/conversations a bit ambiguous.]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“Are the highlighted numbers the only significant findings or just the max scores?”:\n",
      "[Are the highlighted numbers the only significant findings or just the max scores?]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "We agree that the emotion labels are not directly comparable, but machine learning systems trained on one task can often successfully be fine-tuned to transfer learning between them, e.g. as done in the DeepMoji paper which presents results for all these datasets for a same base architecture.\n",
      "\n",
      "\n",
      "[s are not directly comparable]\n",
      "\n",
      "“It would also be helpful to know how more similar emotions such as \"afraid\" and \"anxious\" were scored vs \"happy\" and \"sad\" confusions”: Accuracy reported is not weighted by how “bad” the confusion is, so all the confusions are scored the same: classifying an “afraid” situation as “anxious” is penalized as much as classifying it as “happy”.\n",
      "[It would also be helpful to know how more similar emotions such as \"afraid\" and \"anxious\" were scored vs \"happy\" and \"sad\" confusions]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "- However, as we state in the paper, the definition of coherence can be weakened substantially, and our results still go through.\n",
      "[, the definition of coherence ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Under this *weaker* definition of coherence, the solution set of (SP) need no longer be convex!\n",
      "[ definition of coherence]\n",
      "\n",
      "To see this, consider a very simple optimization example where Player 1 controls x,y in [-1,1], and the objective function is f(x,y) = x^2 y^2 (i.e., Player 2 has no impact in the game, just for simplicity).\n",
      "[ the objective function]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Indeed, the results are only asymptotic - but, as the reviewer states, we know of virtually no other results at this level of generality, and the analysis has to start somewhere.\n",
      "[ the results are only asymptotic]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Regarding the name \"optimistic mirror descent\".\n",
      "[optimistic mirror descent]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Obviously, this is just a sufficient condition, but it is still useful in practice.\n",
      "[ sufficient condition]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“hard to assess whether the reported results are \"accidents\" found in certain images or are general. “\n",
      "\n",
      "\n",
      "[hard to assess whether the reported results are \"accidents\" found in certain images or are general.]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Yet another way of saying the same thing: For a randomly selected image from ImageNet, we found on average 18.5 (25% of 74 translations) different locations where we can vertically translate the location of the embedded image by one pixel and get a change in prediction.\n",
      "\n",
      "\n",
      "[ of the embedded image]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "\"Few quantiative results on the sensitivity to 1-pixel shift, most results are qualitative.\"\n",
      "\n",
      "\n",
      "[Few quantiative results on the sensitivity to 1-pixel shift, most results are qualitative.]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "The size of the embedded image is 150 and figure 6 shows how the size of the embedded image affects performance.\n",
      "[ the size of the embedded image ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "\"results on these networks with larger pooling regions, are all qualitative.\"\n",
      "\n",
      "\n",
      "[results on these networks with larger pooling regions, are all qualitative.]\n",
      "\n",
      "We now have quantitative results (jaggedness and recognition performance) for VGG16 and ResNet50 trained with larger pooling regions (accuracy goes down by about a factor of two, as does jaggedness).\n",
      "[ with larger pooling regions]\n",
      "\n",
      "..\n",
      "\n",
      "\"The mathematical proof is done for average pooling, which is rarely used nowadays\".\n",
      "\n",
      "\n",
      "[The mathematical proof is done for average pooling, which is rarely used nowadays]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "“Also, the aforementioned experiment in which the size of the pooling region is increased, is it max pooling or average pooling?”\n",
      "\n",
      "[Also, the aforementioned experiment in which the size of the pooling region is increased, is it max pooling or average pooling?]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "\"Limited results on the ImageNet bias.\n",
      "[Limited results on the ImageNet bias.]\n",
      "\n",
      "These results are reported in one image category (Figure 5), how general are them? \"\n",
      "\n",
      "\n",
      "[These results are reported in one image category (Figure 5), how general are them?]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "\"The paper assumes that shifting an image embedded an object in a black background is equivalent to shifting an object in a static background.\"\n",
      "\n",
      "\n",
      "[The paper assumes that shifting an image embedded an object in a black background is equivalent to shifting an object in a static background.]\n",
      "\n",
      "Note that we do not use a black background, but rather we use an inpainting procedure to precisely address the reviewer's concern and make sure that no artificial boundaries are created.\n",
      "[ artificial boundaries ]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "\"Theoretical arguments\".\n",
      "[Theoretical arguments]\n",
      "\n",
      "..\n",
      "\n",
      "Regarding piecewise constant transformations: many interesting transformations (e.g. small rotations and scalings) can be approximated by a piecewise constant transformation.\n",
      "[ piecewise constant transformations]\n",
      "\n",
      "..\n",
      "\n",
      "“The theoretical argument that translation invariance is not guaranteed because of the stride (subsampling) is not fully convincing and needs further explanation and experimental verification”\n",
      "\n",
      "\n",
      "[The theoretical argument that translation invariance is not guaranteed because of the stride (subsampling) is not fully convincing and needs further explanation and experimental verification]\n",
      "\n",
      "We prove in the paper (observation at bottom of page 4) that networks with no stride will be translation invariant.\n",
      "[ translation invarian]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "Also, as mentioned in our response to R1, we tried three different types of transformations: inpainting (figure 2), cropping (figure 8) and black border (not shown).\n",
      "[ types of transformations]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n",
      "We very much agree that \"feature maps of the CNNs that the authors consider do indeed contain many high frequencies.”\n",
      "[feature maps of the CNNs that the authors consider do indeed contain many high frequencies.]\n",
      "\n",
      "..\n",
      "\n",
      "\"References and phrasing:\".\n",
      "[References and phrasing:]\n",
      "\n",
      "..\n",
      "\n",
      "..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from difflib import SequenceMatcher\n",
    "import openreview_lib as orl\n",
    "\n",
    "def match_wrapper(sent1, sent2):\n",
    "    match = SequenceMatcher(None, sent1, sent2).find_longest_match(\n",
    "        0, len(sent1), 0, len(sent2))\n",
    "    return sent1[match.a:match.a+match.size]\n",
    "\n",
    "\n",
    "class CommentNavigator(object):\n",
    "    def __init__(self, json_rep):\n",
    "        self.text = json_rep[\"text\"]\n",
    "        self.sentences = [orl.Sentence(\n",
    "        sent[\"start_index\"], sent[\"end_index\"], sent[\"suffix\"],\n",
    "        ) for sent in json_rep[\"sentences\"]]\n",
    "            \n",
    "    def sentence_texts(self):\n",
    "        return [self.text[sent.start_index:sent.end_index]+sent.suffix for sent in self.sentences]\n",
    "    \n",
    "    \n",
    "\n",
    "MatchInfo = collections.namedtuple(\"MatchInfo\", \"review_sentence rebuttal_sentence text\")    \n",
    "\n",
    "max_len = 0\n",
    "\n",
    "\n",
    "\n",
    "for pair in pair_obj[\"review_rebuttal_pairs\"]:\n",
    "    review = CommentNavigator(pair[\"review_text\"])\n",
    "    rebuttal = CommentNavigator(pair[\"rebuttal_text\"])\n",
    "    review_sentences = review.sentence_texts()\n",
    "    max_rev_len = max(len(i) for i in review_sentences)\n",
    "    max_len = max(max_len, max_rev_len)\n",
    "    for reb_i, reb_sent in enumerate(rebuttal.sentence_texts()):\n",
    "        best_match = None\n",
    "        for rev_i, rev_sent in enumerate(review_sentences):\n",
    "            match_text = match_wrapper(rev_sent, reb_sent)\n",
    "            if len(match_text) < 20:\n",
    "                continue\n",
    "            if best_match is None or len(best_match.text) < len(match_text):\n",
    "                best_match = MatchInfo(rev_i, reb_i, match_text)\n",
    "        \n",
    "        if best_match is None:\n",
    "            print(\"..\")\n",
    "        else:\n",
    "            print(reb_sent)\n",
    "            print(\"[\" + best_match.text + \"]\")\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "changed-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "PAIR_FILE = \"review_rebuttal_pair_dataset/traindev_train.json\"\n",
    "\n",
    "with open(PAIR_FILE, 'r') as f:\n",
    "    pair_obj = json.load(f)\n",
    "max_overall_len = 0\n",
    "import openreview_lib as orl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fancy-syndicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227\n",
      "405\n",
      "405\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "491\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "579\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "691\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "717\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "722\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n",
      "898\n"
     ]
    }
   ],
   "source": [
    "class CommentNavigator(object):\n",
    "    def __init__(self, json_rep):\n",
    "        self.text = json_rep[\"text\"]\n",
    "        self.sentences = [orl.Sentence(\n",
    "        sent[\"start_index\"], sent[\"end_index\"], sent[\"suffix\"],\n",
    "        ) for sent in json_rep[\"sentences\"]]\n",
    "            \n",
    "    def sentence_texts(self):\n",
    "        return [self.text[sent.start_index:sent.end_index]+sent.suffix for sent in self.sentences]\n",
    "    \n",
    "\n",
    "\n",
    "for pair in pair_obj[\"review_rebuttal_pairs\"]:\n",
    "    review = CommentNavigator(pair[\"review_text\"])\n",
    "    rebuttal = CommentNavigator(pair[\"rebuttal_text\"])\n",
    "    sentences = review.sentence_texts() + rebuttal.sentence_texts()\n",
    "    max_len = max(len(i) for i in sentences)\n",
    "    max_overall_len = max(max_len, max_overall_len)\n",
    "    print(max_overall_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "authentic-algorithm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Attention clusters: Purely attention based local feature integration for video classification.\"\n",
      "\"consistency constraint\"\n",
      "\"ablation\" or \"accuracy vs trained layers\"\n",
      "\"spherical CNNs\"\n",
      "\"classical\"\n",
      "\"Learning nonlinear dynamical systems using an EM algorithm.\"\n",
      "\"parent distribution\" that can share the nonlinear dynamics operator in the generative model making it more powerful compared. However, this parent distribution is not usable, since it's an intractable variational posterior. Normally, this will prevent variational inference, but the authors take another step by using Laplace approximation to build a \"child distribution\"\n",
      "\"observation\" to \"latent dynamics\"\n",
      "\"extra\" or fake gradient step to get to a new point, and then kind of retracks back and perform a gradient step using the gradient step obtained from the \"extra step\".  This extra-gradient method is a close approximation to Euler's method, though far more computationally efficient.  However, the extragradient step requires one to calculate gradient twice, which can be expensive in large models. For this reason, the authors suggest using gradients from past as the \"extragradient\"\n",
      "\"ExtraAdam\" works better, but the chosen architectures are not state-of-the art. What would convince me if the algorithm can be used to improve a current best inception score of 8.2 reached with SNGANs. Also with WGAN-GP, scores of ~7.8 are reported which are much higher than the 6.4 reported in the paper. But I understand that producing state-of-the-art inception scores is not the focus of the paper, therefore I would suggest that the authors release an implementation of the proposed new optimizers (ExtraAdam) for a popular DL framework (e.g. pytorch) such that practitioners working with GANs can quickly try them out in a \"plug-and-play\"\n",
      "\"more aggressive dropout rates ted to slow down the convergence rate of the model, even if they sometimes result in a higher accuracy\"\n",
      "\"rounds\"\n",
      "\"small-epsilon regime\"\n",
      "\"adversarial vulnerability\"\n",
      "\"growing capacity\"\n",
      "\"the\" in the end of the third paragraph in Related Work. In the last paragraph in Related Work, \"provide\" should be \"provides\". In page 8, the double quotation marks of \"short-term\"\n",
      "\"policy that alters that state of the environment\" to \"policy that alters the state of the environment\"\n",
      "\"local\" context (M steps within a K-long horizon, allowing the method to  recover quickly if learning from contaminated data, and/or its global policy cannot generalize well to the local contexts. Although this extension is trivial it seems that it has not been applied and measured in terms of the adaptation \"speed\"\n",
      "\"contribution\"\n",
      "\"taking into account learned correlations\" in page 5: I suggest changing that to \"taking into account learnable/trainable correlations\" since \"learned correlations\"\n",
      "\"present substantively new ideas or explore an underexplored or highly novel question\"); I do feel confident that some ICLR readers would (perhaps unfairly) describe this approach as \"obvious.\" The paper's presentation suffers, and it fails to communicate essential details clearly. Finally, for folks familiar with healthcare data and MIMIC-III specifically, the results are underwhelming: yes, the proposed approach beats (the authors' own implementations of) baselines, but it underperforms other published results on the MIMIC-III 48-hour mortality task ([1][2] report AUCs of 0.87 or higher). As such, I am assigning the paper a \"weak accept\"\n",
      "\"backprop through time\"\n",
      "\"just memorize the true data distribution\"\n",
      "\"lens\"\n",
      "\"the grid\"\n",
      "\"a gap 7 accuracy\"\n",
      "\"Boosting adversarial attacks with momentum, Dong et al, CVPR18\"\n",
      "\"out-of-the-box\"\n",
      "\"old\"\n",
      "\"interpretation\"\n",
      "\"reparameterization trick\"\n",
      "\"progress\"\n",
      "\"model\"\n",
      "\"generator is injective\"\n",
      "\"parameter-function\"\n",
      "\"simple\" functions, and through a PAC-Bayes argument, the generalization behavior will be good if the target concept is also \"simple\". I like the perspective of view that combines the \"complexity\"\n",
      "\"store forward pass in 4/8 bit fixed point\"\n",
      "\"Quantized neural networks: Training neural networks with low precision weights and activations.\"\n",
      "\"...features that are systematically overestimated by gradient descent.\", \"... i.e., a consequence of gradient descent's inductive bias.\", \"... gradient descent may lead to systematic bias...\"\n",
      "\"Independent\"\n",
      "\"rationalizing textual matching\"\n",
      "\"analogy\" (if we want to translate from French to Spanish but don't know how to do so directly, we should translate from French to English and English to Spanish). It should also be able to generalize better by learning useful \"subfunctions\" that can be composed together by an RL agent. We set up the solution as having a finite number of subfunctions, including \"HALT\" which signifies the end of computation. At each timestep an RL agent chooses a subfunction to apply to the current representation until \"HALT\"\n",
      "\"translated\"\n",
      "\"line graph neural network\" that operate directly over the edges of the graph, using efficiently the power of the \"non backtracking operator\"\n",
      "\"even improve upon current computational thresholds in hard regimes.\"\n",
      "\"content based look-up results... which is not present in the key and need to be retrieved.\"\n",
      "\"true adversarial accuracy\" instead of \"provable adversarial accuracy\" as column header. If the verifiers did not finish, I would include in the paper for how many examples the result was \"adverarial example exists\" and for how many the result was \"timeout\"\n",
      "\"learning a tree\"\n",
      "\"requires taking the inverse square root\"\n",
      "\"log\"\n",
      "\"Sequential Model-Based Optimization approaches are greedy numerical method\"\n",
      "\"P+TG\"\n",
      "\"The accuracy (dotted line in the plots) is the fraction of examples that have been correctly classified for a batch of 10000 samples randomly chosen in the train, validation and test sets.\"\n",
      "\"stale\"\n",
      "\"It might be worth evaluating the usefulness of the method on higher-dimensional examples where the analytic forms of q(x|z) and q(z) are known, e.g. plot KL between true and estimated distributions as a function of the number of dimensions.\"\n",
      "\"marginal\"\n",
      "\"1) to the debate on the harmfulness/importance of selectively activated units in DNNs [1-3] by presenting concrete examples where selectivity is important for generalization, and 2) to the neuroscience community, where, although orientation selectivity has been extensively analyzed for these 60 years since [4], its functional importance in a natural environment has remained unanswered.\"\n",
      "\"orientation selectivity [plays] a causally important role in object recognition\"\n",
      "\"meta-learning\"\n",
      "\"soft\"\n",
      "\"Mapping Instructions and Visual Observations to Actions with Reinforcement Learning.\"\n",
      "\"not smaller\"\n",
      "\"local maxima\"\n",
      "\"random feature grouping\"\n",
      "\"vanishingly small\"\n",
      "\"boundary of set U\"\n",
      "\"simple\"\n",
      "\"F is orthogonal\" does not imply the norm is less than 1, but rather we should say \"F is orthonormal\"\n",
      "\"nonlinearity\"\n",
      "\"performance consistently lags behind that of tree-based models\"\n",
      "\"monotonously\" on p.4 should be \"monotonically\"\n",
      "\"master\"\n",
      "\"Image Restoration with Deep Generative Models.\"\n",
      "\"general method\"\n",
      "\"Calibration methods\"\n",
      "\"main objective\"\n",
      "\"dictionary matrix\"\n",
      "\"In this way, the LISTA model could be further significantly simplified, without little performance loss\"\n",
      "\"will be play\" -> \"will be playing\"\n",
      "\"stochastic generation\"\n",
      "\"of sorts\"\n",
      "\"resets\"\n",
      "\"image classification\"\n",
      "\"we ran numerous simulations\"\n",
      "\"Learning Continuous Hierarchies in the Lorentz Model of Hyperbolic Geometry.\"\n",
      "\"the overall time to read a paper should be comparable to that of a typical 8-page conference paper. Reviewers may apply a higher reviewing standard to papers that substantially exceed this length.\"\n",
      "\"non-linearity\" in the activation patterns on samples belonging to the same class, and correlate that to the level of \"memorization\"\n",
      "\"implies\" -> \"imply\"\n",
      "\"metric\" is that \"reflects the correlation between the true error and the estimated uncertainty ... (and is) scale independent and robust to outliers.\" Given this goal (and the name of the paper) it is perplexing why the correlation (https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) of true error and predicted error (\\sigma_i) was not tried as baseline score. The correlation would have some \"scale independence\"\n",
      "\"For example, in a person’s facial image translation, if the exemplar image has two attributes, (1) a smiling expression and (2) a blonde hair, then both attributes have to be transferred with no other options\"\n",
      "\"value\"\n",
      "\"Causal Reasoning from Reinforcement Learning\", since \"meta-learning\"\n",
      "\"by assuming random weights\"\n",
      "\"Global Guarantees for Enforcing Deep Generative Priors by Empirical Risk\"\n",
      "\"tweaked\"\n",
      "\"effective\"\n",
      "\"simga\"\n",
      "\"abstract\"\n",
      "\"move towards a biologically motivated model of vision\". Are the authors interested in more biologically motivated models because they think they will be useful for some task? Or are the authors interested in models of biological vision itself? If the former, it is unclear what new tasks would be solved by their model (all the results focus on tasks that can be solved without these mechanisms). If the latter, there should be some clear goals for what they hope their model to achieve. \"Moving towards biological vision\"\n",
      "\"Near-optimal entrywise sampling for data matrices\"\n",
      "\"exposure bias\"\n",
      "\"Intra-mode KL divergence\"\n",
      "\"real-world\" programs typically do not exist it necessary to construct a synthetic dataset for training and testing; this requires both (a) generating programs, and (b) generating input/output examples for these programs. Enumerating either all possible programs or examples is typically impossible, and so a sampling scheme is used to simulate \"reasonable\"\n",
      "\"S\"\n",
      "\"covariate\" identity, call into question the very premise of the article. Unlike gender or nationality, I believe that identity is not a \"covariate\" per se. In fact, as argued in Section 3.1, the prediction task for this covariate is not well-defined, as the set of identities in the training, validation and test sets are disjoint. In my opinion, this calls into question the hypothesis that what drives the improved performance is the fact that these models are trained to predict the covariates. Rather, I wonder if the advantages are instead a \"fortunate\"\n",
      "\"state or art\" instead of \"state-of-the-art\"\n",
      "\"far more resources.\" The best ALL-CACO model also relies on several annotated but \"smaller\" resources (dictionaries, parallel text, embeddings). Would it be possible to have a baseline where a target-language model is trained on only a small amount of annotated in-domain document classification data in the target language? I am proposing this baseline in order to answer two questions. (i) Given a small amount of in-domain data for the task at hand, how much benefit do we get from additionally using data from a related language? (ii) How much benefit do we get from using target-language resources that do not address the task directly (dictionaries, embeddings) compared with using a \"similar\"\n",
      "\"loosely related languages\"\n",
      "\"not far behind\"\n",
      "\"In practice, parametric families of functions F such as multi-layer neural networks are used for approximating Lipschitz functions, so that we can empirically optimize this objective eq. (2) via gradient-based algorithms as long as distributions in the family G have parameterized samplers. (See Section 2 for more details.)\"\n",
      "\"properly-designed discriminator architecture\" is not used at all in the experiments in Appendix F. A comparison between a \"properly-designed discriminator architecture\" and a \"vanilla fully-connected distriminator\"\n",
      "\"attention\"\n",
      "\"Success Rate\". That metric is not sufficient for evaluation of navigation agents since it does not include episode length information. All of the results should be based on the protocol mentioned in \"On Evaluation of Embodied Navigation Agents\"\n",
      "\"object-room\"\n",
      "\"our results hold for a more general setting\"\n",
      "\"rethink\"\n",
      "\"constant learning rate\"\n",
      "\"past\"\n",
      "\"Feature Intertwiner\"\n",
      "\"Knockoffs   for the mass: new feature importance statistics with false discovery   guarantees.\"\n",
      "\"pass\"\n",
      "\"vanilla\" Gaussian Variational Auto-Encoders (VAEs) (sections 1, 2, and 3), which are then used to build a new algorithm called \"2 stage VAEs\"\n",
      "\"discriminative\" is a good name for this algorithm. It suggested that is it opposite to \"generative\" (query synthesis?), but then all AL that rank datapoints with some scoring function are \"discriminative\"\n",
      "\"must use at use\" -> \"must use at least\"\n",
      "\"easy\" and \"hard\"\n",
      "\"For the few-shot learning experiments, we found it necessary to downweight the inner KL term for better performance in our model\"\n",
      "\"*approximately* maximizing the marginal likelihood\"\n",
      "\"Variational inference with normalizing flows.\"\n",
      "\"to our knowledge, combining the two statistical results is the first finding in the machine learning field\"\n",
      "\"our model requires choosing c* in the support of P(c) seen during training\"\n",
      "\"new\"\n",
      "\"gradient-based methods\" and \"optimization-based methods\"\n",
      "\"first evidence ... matching the accuracy of full precision\"\n",
      "\"MNIST is not suitable for benchmarking of adversarial attacks\"\n",
      "\"…Grover et al. (Grover et al., 2018)\"\n",
      "\"finding ALL the WORSE regions among trajectory space\"\n",
      "\"significant\". Even though they might be statistically significant (meaning nothing more than the two models being statistically different), minor architectural changes can lead to such improvements. Furthermore PTB is not a \"challenging\"\n",
      "\"time-locked scheduling strategy\"\n",
      "\"log^2(n/delta)\" should be \"log(n^2/delta)\"\n",
      "\"when stags become available, agents care about each other more than just before that happens\"\n",
      "\"encouraging the learned variational posteriors to be diverse\"\n",
      "\"sentiment\"\n",
      "\"a classifier that is separately trained on the resulting encoder representations has an easy time recovering the sentiment\" when the discriminator during training has been fooled. Is there any difference between the two discriminators/classifiers? If the post-fit classifier on top of the encoder representation can easily predict the correct sentiment, there should be enough signal from the discriminator to adapt the encoder in order to learn a more disentangled representation. On the other hand, this does not answer the question if a \"true\" disentangled representation would give better performance. The inferior performance from the adversarially learned models could be because of the \"entangled\"\n",
      "\"style transfer\"\n",
      "\"idealised models\" on \"idealised datasets\" to not have adversarial examples. (In the context of this paper, adversarial examples can either be nearby points that are classified differently with high confidence or points that are \"far\"\n",
      "\"garbage\"\n",
      "\"An overview of dynamic parameter identification of robots\", 2010, and references therein).  This is especially important on the real robot case, where the authors correctly mention that the WAM arm cannot be expressed exactly by the manipulator equations; this makes it all the more important to try identify system parameters via a data-driven approach, not with the hope of finding the exactly \"correct\" manipulator equations, but with finding some that are good enough to outperform the \"analytical\"\n",
      "\"Graph Networks as Learnable Physics Engines for Inference and Control\"\n",
      "\"Classification\"\n",
      "\"feature vector\" to refer to a data point. However, in the context of neural networks, \"feature vector\"\n",
      "\"global memory pointer\" as its last hidden state. The decoder takes as input the global memory pointer, the encoded dialogue state history, and the external KB and then generates a response using a two-step process in which it 1) generates a template response using tags to designate slots that need filling and 2) looks up the correct filler for each slot using the template+global memory pointer as a query. The authors evaluate the model on a simulated dialogue dataset (bAbI) and on a human-human dataset (Stanford Multi-domain Dialogue or SMD) as well as in a human eval. They show substantial improvements over existing models on SMD (the more interesting of the datasets) in terms of entity F1--i.e. the number of correctly-generated entities in the response. They also show improvement on bAbI specifically on cases involving OOVs. On the human evaluation, they show improvements in terms of both \"appropriateness\" and \"human-likeness\"\n",
      "\"our approach that utilizing the recurrent\" or \"in each datasets\"\n",
      "\"deep\"\n",
      "\"the error exponent corresponding to f(x)\" mean? In particular, \"corresponding to f(x)\"\n",
      "\"A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS\"\n",
      "\"Variational autoencoder(VAE) (Kingma & Welling, 2013), compared with AE, has stronger representation capability and can also serve as a generative model\"\n",
      "\"true\"\n",
      "\"defined\" as a mixture of the latent presentations of the input sequence and the mixing weight is the attention. To do inference, maximising VAE-like \"ELBO\"\n",
      "\"we rewrite the inequality as follows\"\n",
      "\"recurrent\"\n",
      "\"We investigated VGG16 (Simonyan & Zisserman, 2014), a standard CNN that closely approximate the ventral visual hierarchical stream, and its recurrent variants for comparison.”, the authors probably meant “coarsely” not “closely\"\n",
      "\"lies within\"\n",
      "\"for convenience, we choose \\mu in such a way that samples from \\mu always consists a mini-batch from X\"\n",
      "\"neural networks suffers..\"\n",
      "\"model's adaptation\"\n",
      "\"Progress & Compress: A scalable framework for continual learning.\"\n",
      "\"Our conjecture also implies that when training a linear downsampling CNN on images of size 3 · 224 · 224, which corresponds to the input image size for VGG and ResNet (He et al. (2016), Simonyan & Zisserman (2015)), the number of linearly independent training examples needs to be at least 3 · 224 · 224 = 153, 228 before the network can learn the identity function.\"\n",
      "\"unknown classes\"\n",
      "\"encourage that either of these two parts (i.e. vectors T_i^u and T_i^v) goes to zero for each sample\"\n",
      "\"average\"\n",
      "\"modified\"\n",
      "\"A Review of Multiple Try MCMC algorithms for Signal Processing\"\n",
      "\"adapt\"\n",
      "\"inductive biases\", which is not clearly defined. How to quantify those biases and how to measure \"generality\"\n",
      "\"GibbsNet: Iterative Adversarial Inference for Deep Graphical Models.\"\n",
      "\"involves calculating the pdf of the logistic mixtures\"\n",
      "\"Transformer-XL\"\n",
      "\"W.\" denotes\"\n",
      "\"Neural Belief Representations\"\n",
      "\"The input to the [evaluation] MLP is the concatenation of b_t and a one-hot of the agent’s initial discretised position and orientation.\"\n",
      "\"deficiency\"\n",
      "\"convergence\"\n",
      "\"Meta-Learning for Stochastic Gradient MCMC\"\n",
      "\"complete recipe for stochastic gradient mcmc\"\n",
      "\"we stress that accuracy on CLEVR is not an end goal in itself\" and \"..CLEVR should be used in conjunction with other VQA datasets in order to study the reasoning abilities of general VQA systems.\"\n",
      "\"run a semantic parsing module to translate a question into an executable program\"\n",
      "\"modes\"\n",
      "\"large modules\" is \"equivalent to solving the optimization problem\"\n",
      "\"combinatorial optimization\"\n",
      "\"invertible boolean logic\"\n",
      "\"if and only if\"\n",
      "\"noisy\" class probability (i.e., the probability of an instance being selected for labeling), just with different losses. While the logistic or \"LSIF\" loss are certainly valid choices, one could use any number of other similar loss (e.g., the exponential loss from class-probability estimation, or the \"KLIEP\"\n",
      "\"unbiased PU learning (PU)\"\n",
      "\"Domain Adaptive Faster R-CNN for Object Detection in the Wild\"\n",
      "\"elephant in the room\"\n",
      "\"A Direct Approach to Robust Deep Learning Using Adversarial Networks\"\n",
      "\"light\") hyperparameter tuning, when the proposed method has many and not discussion is provided about how to set them or how sensitive results are to their actual value. More importantly, the initial claim that uncertainty is better captured relies on SGR, a metric which is not standard and mentioned in passing without being properly defined. The evaluation further depends on a \"selective classifier\"\n",
      "\"The landscape of empirical risk for non-convex losses.\"\n",
      "\"p_i-w\" by assuming that \"p_i(w_0^0) -w\"\n",
      "\"This simple metric is non-parametric and we found that the results are not sensitive to the selection of k\"\n",
      "\"the blind-spot attach\"\n",
      "\"informal\"\n",
      "\"R2DR\"\n",
      "\"We also believe that this paper brings results with a larger scope than the specific problem of designing compact neural networks. Circulant matrices deserve a particular attention in deep learning because of their strong ties with convolutions: a circulant matrix operator is equivalent to the convolution operator with circular paddings\"\n",
      "\"the parameters of GCN and GAT and SRGCN are the same following (Kipf et al; Velickovic et al.)\"\n",
      "\"... framework is shown in Figure X\"\n",
      "\"How does one choose the number of highway layers?\"\n",
      "\"branching\" has been used many times, but AFAIK, this seems not a standard terminology. What do \"branching on the samples\", \"conditional branching\", \"branching paths\"\n",
      "\"at the beginning of training data points from different classes do not activate the same neurons\"\n",
      "\"Independent modes of learning\"\n",
      "\"messy\" in that it is a collection of quite a few findings on the very specific topic of binary classification with quite strong assumptions. Especially given the very specific nature of the topic I miss a strong and clear path through the paper. Unfortunately the paper leaves me with the distinct feeling that there are still a lot of work needed to be able to tell the story about the problem under study. Having said that the paper does contain several individual findings. Having said that I find the ideas leading up to what the authors refers to as \"gradient starvation\"\n",
      "\"under the hood\"\n",
      "\"(5) is exactly the infinite-dimensional analogue of (1):\"\n",
      "\"bilinarization\"\n",
      "\"arbitrary binary classifier\"\n",
      "\"risk rewrite\" is introduced in paragraph 2 with no internal definition and then used subsequently throughout the paper (this defn would be simple enough to give: in the context of this paper, \"risk rewrite\"\n",
      "\"local\"\n",
      "\"Our method ... compares favorably with fully-supervised learning on several classification tasks in the settings studied.\"  This strongly suggests to me that you are claiming to be competitive with SOTA supervised methods.  The paper does not contain supervised results for the resnet-50 architecture.  I would recommend that this sentence should either be dropped from the abstract or have the phrase \"in the settings studied\" replaced by \"for an alexnet architecture\"\n",
      "\"imitation learning benchmark\"\n",
      "\"finish up\"\n",
      "\"new direction\"\n",
      "\"backpropagated\"\n",
      "\"We first define centroids [...]\"\n",
      "\"efficient method for SN in convolutional nets\"\n",
      "\"Obfuscated Gradients Give a False Sense of Security\"\n",
      "\"Neural network ensembles, cross validation, and active learning.\"\n",
      "\"unsupervised exploration\" was mentioned a few times in this paper. I am not sure if this is an accurate term. Is there a corresponding \"supervised exploration\"\n",
      "\"dynamic oracle\"\n",
      "\"Cold-Start Reinforcement Learning with Softmax Policy Gradient.\"\n",
      "\"NN has achieved\" => \"Neural Networks have achieved\"\n",
      "\"help desk\"\n",
      "\"egregious\" outputs (\"I will kill you\"\n",
      "\"l1 + projection\"\n",
      "\"proportion\"\n",
      "\"we sometimes write a predicate \\phi to denote its indicator function 1_\\phi\"\n",
      "\"Adversarial Sets for Regularising Neural Link Predictors\"\n",
      "\"Neural Ordinary Differential Equations.\" arXiv preprint arXiv:1806.07366 (2018). Chapter two of this paper is summary of  \"Neural Ordinary Differential Equations.\"\n",
      "\"locally\"\n",
      "\"random\"\n",
      "\"otime\" yields product measures) (it is likely that similar connections could be made with the \"static\"\n",
      "\"transfer to different models\"\n",
      "\"security-through-obscurity\"\n",
      "\"primarily tools of basic research, and not models of real-world security scenarios\"\n",
      "\"DeepMind Atari\"\n",
      "\"max-marginal regularization\" which is a linear combination of log-likelihood and max-margin (where the score is given by log-likelihood) losses. Firstly, the use of word \"marginal\" instead of \"margin\"\n",
      "\"universal\"\n",
      "\"discounted\") proximity function. Wouldn't a linear function of \"step\"\n",
      "\"increasing\"\n",
      "\"specially adapted for accelerating the convergence velocity of networks by [the authors]\"\n",
      "\"automatic rejection\"\n",
      "\"-0.25, -0.125, 0\"\n",
      "\"important\"\n",
      "\"On revisions\"\n",
      "\"Conditional Entropy Bottleneck\" (CEB), motivated by learning better latent representations. However, as far as I can tell, the objective functions already exists in the one-parameter family of Information Bottleneck (IB) of Tishby, Pereira, and Bialek. The author seems to realize this in Appendix B, but calls it \"a somewhat surprising theoretical result\"\n",
      "\"complementary-label\"\n",
      "\"mixing matrix\"\n",
      "\"feed\" instead of \"fed\"\n",
      "\"cleaning\"\n",
      "\"the best result obtained from each choice of \\alpha^m \"\n",
      "\"o'\"\n",
      "\"r\"\n",
      "\"first\"\n",
      "\"Wikispeedia\" dataset, in which nodes are connected in a graph, but a datapoint (a wikispeedia \"game\"\n",
      "\"backprop\"\n",
      "\"Probabilistic Embedding of Knowledge Graphs with Box Lattice Measures\"\n",
      "\"inspired by\"\n",
      "\"fast\"? Is it \"slow\"\n",
      "\"information flow\"\n",
      "\"non local means filtering\". The underlying assumption seems to be that, at feature level, adversarial examples manifest as IID noise in feature maps, which can be \"filtered away\"\n",
      "\"neuroscience motivation\"\n",
      "\"phonemes and ctc\"\n",
      "\"I don't know\"\n",
      "\"online\" nor \"offline\"\n",
      "\"kernel\"\n",
      "\"micro-\" patches, being passed as input a latent vector and patch co-ordinates. Micro-patches generated for different adjacent locations with the same latent vector are combined to generate a \"macro\" patch. This \"macro\"\n",
      "\"Non-local neural networks.\"\n",
      "\"The motivation is to make each temporal Gaussian distribution specify (temporally) ‘where to look’ with respect to the activity center, and represent the activity as a collection/mixture of such temporal Gaussians convolved with video features.\"\n",
      "\"We can confirm that the model can control both location and object's shape\"\n",
      "\"simple replacements\"\n",
      "\"attention\"\n",
      "\"To the best of our knowledge, this is the first time to consider residual non-local attention for image restoration problems.\"\n",
      "\"NTIRE 2018 Challenge on Single Image Super-Resolution: Methods and Results\"\n",
      "\"sparsest vector in the subspace\"\n",
      "\"...or are formulated as a sequence of discrete actions needed to construct a graph, making the output graph non-differentiable w.r.t the model parameters...\"\n",
      "\"selecting the temperature of the resampling distribution to not be too low.\"\n",
      "\"We design a new algorithm, Sequential Monte Carlo Planning (SMCP), by leveraging modern methods in Sequential Monte Carlo (SMC), Bayesian smoothing, and control as inference\"\n",
      "\"control as inference\"\n",
      "\"Composing graphical models with neural networks for structured representations and fast inference.\"\n",
      "\"SG steps\" and \"Epochs\"\n",
      "\"A review of instance selection methods.\"\n",
      "\"train\"\n",
      "\"... may be easily determined via standard hyperparameter optimization methods\" vs. \"tuning \\lambda to directly satisfy the desired fairness metrics\". Or even more unclear - \"choose \\lambda ... so that the final solution gives the desired fairness-accuracy trade-off\"\n",
      "\"Lowering the learning rate for re-training can diminish heavy changes in the weight distribution, at the cost of longer time to converge and the risk to get stuck at plateau regions, which is especially critical for trainable scaling factors\"\n",
      "\"Measuring abstract reasoning in neural networks.\"\n",
      "\"...  Finetuning from GLOM, helped NES achieve stronger performance, nearly identical to the fully-supervised upper bound. It performed better than finetuning from AM (which achieved 22.5/0.85 and 22.7/0.86)\"\n",
      "\"universal set\"\n",
      "\"vanilla\"\n",
      "\"Reinforcement Learning for LTLf/LDLf Goals.\"\n",
      "\"hard\"\n",
      "\"Lfake itself consists of assessment for noise- (xˆz∼N(0,1)) and data-conditioned (xˆz∼N(µz|x,Σz|x)) hypotheses and the best guess given by the WTA objective.\"\n",
      "\"For simplicity, imagine an ... the real distribution.\"\n",
      "\"excitation\"\n",
      "\"After convergence, ED demonstrates a significant improvement in performance compared to other methods\"\n",
      "\"tend to work only under limited scenarios\" while PR2 is more general, then it would be fair to ask for a comprehensive comparison of PR2 vs alternatives in at least 1 such scenario. I would be interested to see how the classical family of \"Win or Learn Fast\"\n",
      "\"Max of Two Quadratics\"\n",
      "\"self-play\"\n",
      "\"Memory Bounded Deep Convolutional Networks\"\n",
      "\"p_n(\\ell)\"? What is \"p-th percentile of a distribution\"\n",
      "\"noise\"\n",
      "\"regular writing\" method as well as compare against each other, namely \"uniform writing\" and \"cached uniform writing\". Latter one attempts to utilize a small size memory efficiently by introducing memory overwriting in other words \"forgetting\"\n",
      "\"Uniform Writing\" (UW) which updates the memory at regular intervals instead of every timestep. The derivation is based on the \"contribution\"\n",
      "\"a_{t, j} is the attention score\" but you should have \"\\alpha_{t, j} is the attention score\"\n",
      "\"desirable slow decay\"\n",
      "\"encourages a slow singular value decay\"\n",
      "\"(2) Limited Context and/or Smaller training corpus of documents: In settings with a small number of word occurrences (i.e., lack of context) in short text or data sparsity in a corpus of few documents, the application of TMs is challenging.\"\n",
      "\"the topic assigned ...equally depends all the other words appearing in the same document\"\n",
      "\"After extracting the region from the image, the region is resized to be of the size required by the network.\"\n",
      "\" doesn’t seem to be a standard approach. In the attentional LSTM, the use of “parse LSTM” is also not a standard approach in seq2seq models and doesn’t seem to work well in the experiment (similar result to “Simple LSTM\"\n",
      "\"Deep Neural Solver for Math Word Problems\"\n",
      "\"soft\"\n",
      "\"Phrased\"\n",
      "\"to let our presentation stay focused (...)\"\n",
      "\"we could obtain\" and simply write \"we obtain\"\n",
      "\"neighbors also to increases\" (drop \"to\"\n",
      "\"samples\"\n",
      "\"The segmentation decisions and decisions\"\n",
      "\"good\"\n",
      "\"How much does the training scheme know about the particulars of the problem?\", ranging from \"Literally has oracle access to the weights of the trained model (i.e., trivial, MC-hardness = 0 always)\" to \"knows what the architecture of the held-out-layer is and has been designed to optimize that particular network (see, e.g., learned optimizers)\" to \"knows a little bit about the problem structure, and uses hyperparameter tuned ADAM\" to \"knows nothing about the problem and picks a random* architecture to use for the held out weights, training it with SGD\"\n",
      "\"Large Margin Deep Networks for Classification\"\n",
      "\"train valid set\"\n",
      "\"unsupervised\" manner, but it is unclear what this means. Previous work (none of which is cited) has dealt with unsupervised option discovery in the context of mutual information maximization (Variational intrinsic control, diversity is all you need, etc), but they do so in the absence of reward, unlike this paper. \"Optimal policy\"\n",
      "\"neural brainwashing\"\n",
      "\"Understanding and simplifying one-shot architecture search.\"\n",
      "\"true\"\n",
      "\"thinking\"\n",
      "\"MCMC & VI: Bridging the Gap\"\n",
      "\"Because MPFs are equivalent to ergodic Markov chains, the density obtained at the output of an MPF, that is, qL, will converge to the stationary distribution π as L increases.\"\n",
      "\"no unmeasured confounding\"\n",
      "\"reconstruction\"\n",
      "\"goal-conditioned\" formulations for hierarchical control in Reinforcement Learning. In this problem, a low-level controller is incentivized to reach a goal state designated by a higher-level controller. This goal is represented in an abstract (embedding) multi-dimensional vector space. Establishing \"closeness to goal\" entails the existence of some distance metric (assumed to be given an fixed) and a function $f$ which can project states to their corresponding goal representation. The \"representation learning\" problem referred to by the authors pertains to this function. The paper is built around the question: how does the choice of $f$ affects the expressivity of the class of policies induced in the lower level controller, which in turn affects the optimality of the overall system. The authors answer this question by first providing a bound on the loss of optimality due to the potential mismatch between the distribution over next states under the choice of primitive actions produced by a locally optimal low-level controller. The structure of the argument mimics that of model compression methods based on bisimulation metrics. The model compression here is with respect to the actions (or behaviors) rather than states (as in aggregation/bismulation methods). In that sense, this paper is a valuable contribution to the more general problem of understanding the nature of the interaction between state abstraction and temporal abstraction and where the two may blend (as discussed by Dietterich and MAXQ or Konidaris for example). Using the proposed bounds as an objective, the authors then derive a gradient-based algorithm for learning a better $f$. While restricted to a specific kind of temporal abstraction model, this paper offers the first (to my knowledge) clear formulation  of \"goal-conditioned\"\n",
      "\"alternating\" should be alternative and \"synthetical\"\n",
      "\"capturing correlations\"\n",
      "\"Convolutional 2d knowledge graph embeddings.\"\n",
      "\"The the\" -> \"The\"\n",
      "\"deep learning\"\n",
      "\"concrete distribution\" or \"Gumbel-Softax distribution\"\n",
      "\"Summary of Results\"\n",
      "\"semantics\" of the data was defined. Is it given by visual inspection? Is it possible to find it with some automated method? Second, the authors seem to advocate the idea that data of a k-mode distribution should be generated from a k-mode latent distribution. It might be useful in certain scenarios; however, it is not clear why the transformation from the latent to the observed does not change the number of modes or why keeping the same number of modes would endow the latent distribution a \"semantics\" meaning. We know that a k-mode distribution can be obtained by applying a smooth nonlinear transformation to a Gaussian or uniform distribution and, similarly, a k-mode distribution can be transformed to a single-mode distribution with a smooth mapping. So I am not sure why engineering the latent distribution this way can give it a \"semantics\"\n",
      "\"AC-GAN Learns a Biased Distribution.\"\n",
      "\"are intentionally selected by us for evaluating the performance of inverse dynamics model, as each of them allows only a very limited set of chained actions\"\n",
      "\"Demos\"\n",
      "\"a\",  it will be more clear if the authors use another symbol to denote the parameter of q(z) instead of \"\\alpha\"\n",
      "\"that a coupled through a communication medium\" -> \"that are coupled through a communication medium\"\n",
      "\"we do not assume the existence of explicit rewards guiding the communication action,\" which however is questionable.  The \"extrinsic reward\"\n",
      "\"GAIN: Missing Data Imputation using Generative Adversarial Nets\"\n",
      "\"like\"\n",
      "\"sub-optimal\" demonstrations to the expert demonstrations, but down-weighting each sub-optimal demonstration be a factor of \\lambda. Thus, I don't believe we need to introduce an entirely new algorithm, with the concept of a 3rd class, to solve this problem. The existing MaxEnt frameworks seem to handle the notion of sub-optimality proposed in this paper just as well, interpreting the \"sub-optimal\"\n",
      "\"[...]due to its dependent[sic] on the linearity of reward functions and good feature engineering\"\n",
      "\"knowledge distillation loss\"\n",
      "\"deep\"\n",
      "\"Pointer Sentinel\" model can achieve. Without edges connecting the additional words to where they occur, it seems that this should not be performing different than \"Closed Vocab\"\n",
      "\"improvement\"\n",
      "\"recovering y_i\"\n",
      "\"to propose methods that can help to understand the intricacy and complexity of human motivations and their behaviors\"\n",
      "\"noisy labels\"\n",
      "\"more direct\"\n",
      "\"Our paper resolves the question posed in ICLR Best paper 2017 \"Understanding deep learning requires rethinking generalization\"\"\n",
      "\"When to Finish? Optimal Beam Search for Neural Text Generation\"\n",
      "\"copies\" (of the source sentence) when using large beam widths, which results in degraded results. In particular, the present paper observes similar shortcomings in two additional tasks (summarization and captioning), where decoding with large beam widths results in \"training set predictions.\"\n",
      "\"simpler\"\n",
      "\"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper\"\n",
      "\"regularizing\"\n",
      "\"if the distribution p(x) is unknown, then constructing an explicitly orthonormal function basis may not be possible\"\n",
      "\"exponentiated payoff distribution,\"\n",
      "\"Cons\"\n",
      "\"compound questions\" instead of \"multi-hop questions\". In my opinion, \"multi-hop questions\"\n",
      "\"most\" (\"most of the dots are red\"\n",
      "\"invertible\"\n",
      "\"discriminative objective\", but \"adversarial\" (i.e. featuring a discriminator) and \"discriminative\"\n",
      "\"are not commonly appeared\"\n",
      "\"hints\"\n",
      "\"true\"\n",
      "\"A multi-batch l-bfgs method for machine learning.\"\n",
      "\"close\"\n",
      "\"Unsupervised Predictive Memory in a Goal-Directed Agent\" arXiv:1803.10760 and Ha & Schmidhuber \"World Models\"\n",
      "\"mathiness\". I'm giving the paper a borderline accept because the idea is interesting and the results are OK; I will raise my score if Section 3 is dramatically improved. I give some specific examples of issues with Section 3 in my specific comments below. I'd also note that the paper does a somewhat poor job comparing to existing work - only section 4.2 includes a comparison to existing \"uncertainty\" methods. This should also be improved - the authors should implement the existing methods and use them as a point of comparison in all of their experiments. As a final high-level note, the approach is described at various points as an \"autoencoder\" particularly in reference to the adversarial autoencoder. However, the approach does not \"autoencode\"\n",
      "\"hypernetwork\"\n",
      "\"Clamped\"\n",
      "\"we optimize the holistic metrics over the hierarchy by providing the policy network with holistic rewards\"\n",
      "\"Regularizing neural networks by penalizing confident output distributions.\"\n",
      "\"But for our regularized model, the number of weights with high values is smaller compared to that of normal model ...\"\n",
      "\"Increasing the batch size beyond a certain point yields no improvement in wall-clock time to convergence, even for a system with perfect parallelism.\"\n",
      "\"pretend-to-share\"\n",
      "\"pretend-to-share\" problem that models \"collect all the features together into a common space, instead of learning shared rules across different tasks\"\n",
      "\"We found that the improvement on VAT is not drastic – our base implementation obtains 11.26% error where fast-SWA reduces it to 10.97%\"\n",
      "\"An state\"\n",
      "\"intrinsic reward\" bonuses to novel states (curiosity-driven exploration) , trying to reach various goals (goal-driven exploration) and using memory to reach again novel states (memory-driven exploration). Actually, this split may be debated. For instance, some frameworks based on goals have been labelled curiosity-driven, e.g. \"Curiosity-Driven Exploration of Learned Disentangled Goal Spaces\" (Laversanne-Finot, Péré and Oudeyer, CoRL 2018), but anyways I find it useful. That said, this aspect of the introduction is reiterated in the \"Related Work\"\n",
      "\"Self-Imitation Learning,\" \"Automatic Goal Generation for Reinforcement Learning Agents,\" and \"Curiosity-driven exploration by self-supervised prediction\"\n",
      "\"warm-up\" phase are actual costs, and given the inherent sample complexity challenges of reinforcement learning, I would expect them to be significant in practice.  This would be fine if the setup is \"we have a fixed offline set of examples where all features have been acquired (full cost paid) from which we will learn a selector+predictor for test time\"\n",
      "\"fully differentiable\"\n",
      "\"learned non-linear recurrent combinations\"\n",
      "\"Adversarial Time-to-Event Modeling\"\n",
      "\"BPGrad: Towards Global Optimality in Deep Learning via Branch and Pruning\"\n",
      "\"frames\"\n",
      "\"so what?\"\n",
      "\"A Neuroevolution Approach to General Atari Game Playing\"\n",
      "\"genetic algorithm\"\n",
      "\"Learning Hawkes Processes from Short Doubly-Censored Event Sequences\"\n",
      "\"Accurate Uncertainties for Deep Learning Using Calibrated Regression\"\n",
      "\"Bayesian statistics make use of the predictive distribution to infer a random variable by computing the expected value of all the possible likelihood distributions. This is done under the posterior distribution of the likelihood parameters\"\n",
      "\"collocated\"\n",
      "\"source domain encoder\"\n",
      "\" Choice of Proposal density \"\n",
      "\"Auxiliary variational method\"\n",
      "\"fills out\"\n",
      "\"weak accept\"\n",
      "\"binaryconnect method fails\" and \"our method [...] outperforms all the existing quantization methods\"\n",
      "\"In this paper, we relaxes the ...\"\n",
      "\"Since the data were not Gaussian, the second-order matching method has the lowest power. The assumptions of the Fixed knockoff generations holds for the Gaussian cases, …\"\n",
      "\"a model with following components\"\n",
      "\"Noisy Information Bottlenecks\". The overall idea is that, if the mutual information between learned parameters and the data is limited, then this prevents overfitting. It proposes to create a \"bottleneck\"\n",
      "\"restricting the family of variational approximations can, in fact, have a positive regularizing effect, leading to better generalization\"\n",
      "\"Our main finding is that, when compared carefully, a conventional neural Language Model performs at least as well as any of the tested GAN models\"\n",
      "\"A progressive batching L-BFGS method for machine learning.\"\n",
      "\"accidents\" found in certain images or are general. The results that support that 1-pixel shifts affect state-of-the-art neural networks are in Figure 2b. Yet, these results are unclear, eg. is \"400 Jaggedness\" a lot?, what is the size of the embedded image?, How are the 100 images selected? Is the network performing well in those images? How does the size of the embedded image change the \"Jaggedness\"\n",
      "\"Implications for Practical Systems\"\n",
      "\"zero-shot\"\n",
      "\"Dayan & Hinton (1997); Levine (2018); Abdolmaleki et al. (2018) study in a probabilistic inference perspective.\"\n",
      "\"Shift\"\n",
      "\"Random Test Accuracy\" and the \"Classification Accuracy\"\n",
      "\"dead\"\n",
      "\"fail\"\n",
      "\"a strong theoretical advantages\"\n",
      "\"planning\"\n",
      "\"Multilinear Analysis of Image Ensembles: TensorFaces,\"\n",
      "\"logits\"\n",
      "\"parameter attention\"\n",
      "\"skip\" and \"resnet\"\n",
      "\"depicted\"\n",
      "\"contexts\" of the entities as they occur in associated text corpora (e.g. Wiki) in the proposed neural-network based embedding approach for this task. The key novelties of the approach lie in the \"matching\"\n",
      "\"information curve\" (i.e. I(T;Y) as a function of I(X;T)) is piece-wise linear and, thus, no longer strictly concave, which is crucial for non-degenerate (\"interesting\"\n",
      "\"Information Bottleneck curve\"\n",
      "\"progress monitoring\"\n",
      "\"self-aware\") approach is its ability to reason over which aspects of the instruction have been completed, which are to be followed next, which direction to go in next, as well as the agents current progress. This involves two primary components of the architecture. The first is a visual-textual module that grounds to the completed instruction, the next instruction, and the next direction based upon the visual input. The second is a \"progress monitor\"\n",
      "\"We show that deep generative networks perform better than other standard methods of estimating probability measures when the measure satisfies the disconnected support property.\" This claim is essentially from Lemma 3, and it is a property of deep generative networks instead of GANs. If we have another way to train deep generative networks (say, variational auto-encode), we still get the same good approximation error, just linearly dependent of the number of disconnected pieces. The proof of Lemma 3 is mainly from the definition of locally smoothness and the results in Petersen & Voigtlaender 2017. It's a nice effort to leverage the result in Petersen & Voigtlaender 2017 to prove approximation properties of deep generative models. The flaw of this part is that the claims of other standard methods (Proposition 1) is very hand-wavy and floppy. The proof of Proposition 1 has lots of typos. For example, the definition of S_1 and S_2. And this sentence \"Then, by the proof of Lemma 1, p2(x) on S2 is a quadratic function with respect to z1 is 1-times differentiable but not twice-differentiable at the boundary ...\" I guess that the authors want to argue that traditional function approximation methods (like Kernel methods, polynomial approximation) all have rate n^{-1/(2+D)} approximation rate in the L^2 norm when the function to approximate has discontinuities... However, the authors fail to make this point clear. Moreover, if we use a mixture model of traditional approximations, the rate will not be deteriorated.  And we will get similar results in Lemma 3. Then, even the claim \"deep generative networks perform better than other standard methods of estimating probability measures when the measure satisfies the disconnected support property\"\n",
      "\"we can show that GANs can adapt to disconnected supports (under these other assumptions) that has not previously been shown for other methods.\"\n",
      "\"there’re\", \"the network could be more aware of what it’s exactly doing\", \"discriminator loss given its popularity and mightiness to achieve adversarial learning\"\n",
      "\"dreaming\"\n",
      "\"world model\"\n",
      "\"behavior\"\n",
      "\"good\"\n",
      "\"Transfer Learning with Label Noise.\" arXiv preprint arXiv:1707.09724 (2017). and Liu, Tongliang, and Dacheng Tao. \"Classification with noisy labels by importance reweighting.\"\n",
      "\"End-to-end Active Object Tracking and Its Real-world Deployment via Reinforcement Learning\", as the only two additions are extra observations o_t^{alpha} for the target, and a reward function that has a fudge factor when the target gets too far away. Citing Sun Tzu's \"Art of War\"\n",
      "\"partial zero sum\"\n",
      "\"evidence\"\n",
      "\"circus\" vs \"zoo\"\n",
      "\"... apply the net update factor to study the behaviors of Adam using Equation 6 as an example. The argument will be extended to the stochastic online optimization problem and general cases.\"\n",
      "\"theorem\", the results of theorem 2 and 3 limited to the example of failure given in eq 6. I would have been more humble, and called such analyses \"lemma\"\n",
      "\"The specific shaping rewards use for soccer are detailed in Section 4.2\"\n",
      "\"distributionally robust optimization\"\n",
      "\"In specific\" --> \"Specifically\" in the abstract, \"computational budge\" -> \"budget\"\n",
      "\"discriminator\"\n",
      "\"Adversarial discriminative domain adaptation.\"\n",
      "\"for different choices of dropout rate the baseline can always be improved by...\"\n",
      "\"embed solvers as a replacement to their corresponding blocks of layers\"\n",
      "\"hash\"\n",
      "\"The method uses the factorized embedding model (Trofimov et al., 2017) combined with an RNN.\"\n",
      "\" --> incomprehensible \"corresponding?\" \"possible responds?\" do you mean \"response\"\n",
      "\"Wasserstein distance\"\n",
      "\"Tacotron2\" is often referred to Shen et al.'18, not Skerry-Ryan et al.'18. Consider using something like \"Prosody-Tacotron\"\n",
      "\"in the same function space\"\n",
      "\"ROAD: Reality Oriented Adaptation...\"\n",
      "\"trivial\"\n",
      "\"invented\"\n",
      "\"softmax algorithm\" and \"classification behaviour.\"\n",
      "\"Notice that the gradient vector is computed at w_t instead of w_{t−1/2}\" why would it be $w_{t-1/2}$ ? in comparison to what ? \"Also, w_{t+ 1/2} is updated from {w_{t− 1/2} instead of w_t.\"\n",
      "\"optimism\"\n",
      "\"practical\"\n",
      "\"Optimistic Adam\"\n",
      "\"no decoder\"\n",
      "\"extreme code summarization\"\n",
      "\"this is computationally infeasible due to the vast number of unique chunks\" is not completely true as HRR have been used to represent trees in \"Distributed Tree Kernels\"\n",
      "\"stratified SSL.\"\n",
      "\"Semi-supervised learning literature survey.\"\n",
      "\"spoil the network\", \"model is spoiled\", \"problem of increased classes\", \"many recent researches have been conducted\", \"lots of things to consider for training\", \"supervised learning was trained\"\n",
      "\"the f-divergence is generally computationally intractable for such complex models. The main contribution of our paper is the introduction of an upper bound on the f-divergence.\"\n",
      "\"This viscosity solution u(w, t) makes f(w) more convex by bringing down the local maxima while retaining the wide minima.\" Besides illustrating such a point on some nicely constructed function f, is there any theory or analysis supporting this statement? Or is there any intuition behind it? In the abstract and Section 1, how to define a function is \"more convex\"\n",
      "\"cheating\").  That is helpful, though it doesn't give a complete picture yet.  The explanation about the link to the \"more convex\"\n",
      "\"minimal random coding\"\n",
      "\"small scale\"\n",
      "\"no-regret algorithm\". you then extend this notion and claim \"if we can achieve low regret .... then ....\"\n",
      "\"go\"\n",
      "\"random network distillation,\" a method that adds an additional reward based on a proxy for \"exploration\"\n",
      "\"intrinsic reward\"\n",
      "\"Discussion on whether the condition happens in real practice\" below Theorem 2 seems not correct to me. Even when layer normalization is employed and bias is not zero, the convex hull can still contain the origin as long as the length of the bias vector is less than 1. In fact, this condition seems fairly strong, and surely it will not hold \"almost for sure in practice\"\n",
      "\"background texture\"\n",
      "\"The variational fair autoencoder.\"\n",
      "\"domain classification network\" and also \"domain confusion network\"\n",
      "\"music translation\". To this end, an autoencoder model is constructed, where the decoder is autoregressive (WaveNet-style) and domain-specific, and the encoder is shared across all domains and trained with an adversarial \"domain confusion loss\"\n",
      "\"with the larger road network, the difficulty of flow forecasting grows.\"\n",
      "\"why are current RL algorithms so inefficient in transfer learning\" and (2) \"what kind of RL algorithms could be friendly to transfer learning by nature\"\n",
      "\"Notations and Pseudocodes\" is confusing and has many undefined notations which makes the paper very hard to read. It gives the impression that the section was added the last minute. For example what is fundtion \"g\"\n",
      "\"whitening layer\"\n",
      "\"Pruning Convolutional Neural Networks for Resource Efficient Inference\"\n",
      "\"Baseline\"\n",
      "\"student distinguisher\" and several \"teacher distinguishers\"\n",
      "\"to exclude any cost objective\"\n",
      "\"exactly the desired trade-off between reward and cost\"\n",
      "\"expectation (E)\"\n",
      "\"photometric BA\"\n",
      "\"depth bases\"\n",
      "\"We take Schaul's UVFA, make it recurrent, use the IMPALA set up of Esspholt, and show generalization to new combinations of objects to be collected as goals\"\n",
      "\"single-stage end-to-end learning\". The resulting \"Unicorn\" agent trains on all tasks simultaneously. The idea is to use multi-task \"off-policy learning\"\n",
      "\"While effective, these filters ... as according to Eq. (2) filter...\" -> article missing for the word \"filter\"\n",
      "\"if statements\"\n",
      "\"characteristic magnitude of the weights\"\n",
      "\"adversarial training on latent space interpolations encourage[s] convex latent distributions\". A convex latent space is defined as a space in which a linear interpolation between latent codes obtained by encoding a pair of points from some data distribution yields latent codes whose decoding also belongs to the same data distribution. The authors argue that current leading approaches fall short of producing convex latent spaces while preserving the \"high-dimensional structure of the original distribution\"\n",
      "\"generator\" autoencoder is trained to fool a \"discriminator\"\n",
      "\"feed-forward\"\n",
      "\"humans\"\n",
      "\"asymptotic\"\n",
      "\"alt-az rotation group\"\n",
      "\"to extract non-trivial features\". The word non-trivial really doesn't add anything here. Similarly \"offers multi-level feature extraction capabilities\"\n",
      "\"quantify\"\n",
      "\"relevant\"\n",
      "\"sup\"\n",
      "\"Each sequence contains n images, and each image corresponds to an integer label. Our goal is to learn to predict the permutation that sorts these labels\"\n",
      "\"s\"\n",
      "\"it is in general impossible to find an embedding in R^d such that ...\"\n",
      "\"The results are shown in Table 5\"\n",
      "\"The stochastic process (X_t, Y_t) is Gaussian\"\n",
      "\"density estimations\". In other words, no \"practical\"\n",
      "\"measurement process\"\n",
      "\"edge probabilities\" over different precision in any way the function of the input (image)? It seems your approach is able to distinguish \"easy\" and \"hard\"\n",
      "\"the value of \\sigma seems to not matter too much\"\n",
      "\"class number\" not \"number of classes\"\n",
      "\"transferable;\" it would be helpful if the authors clarified what they mean by this. Nevertheless, as the paper suggests in the introduction that symbolic representations are less likely to overfit to the training distribution, I would be interested to see an experiment that illustrates the capability of the program-augmented policy to generalize to new tasks. For example, Ellis et al. [1] suggested that the programs can be leveraged to extrapolate to problems not previously seen in the input (e.g. by running the for loop for more iterations). To show the transferability of such symbolic representations, is it possible for the authors to include an experiment to show to what extent the perceptor gradients algorithm can generalize to new problems? For example, is it possible for the proposed approach to train on \"Minecraft: Go to Pose\"\n",
      "\"symbolic\" (I'd be happier if we could just call them \"discrete\"\n",
      "\"fake\" samples and \"true\"\n",
      "\"synthetic\"\n",
      "\"\\rightarrow\"\n",
      "\"substantially worse\"\n",
      "\"Loss\" be \"Error\"\n",
      "\"If the entries are too large, then θ̂ φ will not be flexible enough to capture the best- response over the sampled neighborhood. However, its entries must remain sufficiently large so that θ̂ φ captures the local shape around the current hyperparameter values.\"\n",
      "\"score-based\"\n",
      "\"SynthNet\" is suggestive but any music generated by such an audio model could be considered \"synthesized\".)  Using a SoundFont instead of \"real\"\n",
      "\"style\" to mean \"timbre\"\n",
      "\"is substantially better in quality\"\n",
      "\"Learning to Write with Cooperative Discriminators\", Holtzman et al., ACL 2018.  That paper also includes many specified aspects to improve the coherence (from the abstract of that paper \"Human evaluation demonstrates that text generated by our model is preferred over that of baselines by a large margin, significantly enhancing the overall coherence, style, and information of the generations.\"\n",
      "\"coherence discriminator\" which takes as input all of the sentence embeddings (i.e. averaged word embeddings) of the document and assigns a score, and a \"cohesion discriminator\"\n",
      "\"neural revolution\"\n",
      "\"GPUs.\"\n",
      "\"It is highly undesirable to converge to Nash in this game\"\n",
      "\"convergence to fixed point\"\n",
      "\"Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders\". It's great that they used that paper as their baseline. The extension is to use a GAN objective function (the discriminator) as critic and use Wasserstein GAN to to resolve the gradient vanishing issue and produce smooth gradients everywhere. In ACL 2017 paper they use KL divergence to make the posterior from the prior and rec-networks as close to each other so at test time the prior network can generate the samples similar to the true data features distribution. In this paper instead of KL, they use a Discriminator as in 'Adversarial AutoEncoders' paper. This paper extends AAE, instead uses the Wasserstein distance instead (1-Lipschitz function instead of softmax for the discriminator). The W-GAN has been shown to produce good results in text generation in this year's ICML 2018 with the paper 'Adversarially Regularized GAN' (AARE). The idea was to resolve VAE posterior collapse issue by using a discriminator as a regularizer instead of KL divergence with a stronger sampler from the output of the generator to map from noise sampler into the latent space. Interestingly, AARE paper is not cited in this work, which i think is an issue. I understand that paper was just for generation purpose not specific to the dialog modeling, but it makes the claims in the paper misleading such as: \"Unlike VAE conversation models that impose a simple distribution over latent variables, DialogWAE models the data distribution by training a GAN within the latent variable space\"\n",
      "\"side e\", what is a \"side\"\n",
      "\"Interactive, graphical processing unit- based evaluation of evacuation scenarios at the state scale\"\n",
      "\"relatively few parameters\"\n",
      "\"separates\"\n",
      "\"percent of features masked\"\n",
      "\"three ways forward\"\n",
      "\"l_p adversarial example\" definition in literature. The main idea involves looking at the preimage of different embeddings in the final layer of an invertible neural network. By training a classifier on top of the final embedding of the invertible network the authors are able to partition the final embedding into a set of \"semantic variables\", which are the components used for classification of the classifier, and a set of \"nuisance variables\"\n",
      "\"reuse\"\n",
      "\"encoder\" network maps the image to some latent code vector, (2) a \"decoder\"\n",
      "\"label graph\"\n",
      "\"useful\"\n",
      "\"end-to-end training of binary networks crucially relies on the optimiser taking advantage of second moment gradient estimates\"\n",
      "\"nearly closed form\"\n",
      "\"Further, for each s, let λs be the solution to \"\n",
      "\"dense\"\n",
      "\"information density\"\n",
      "\"reversible\"\n",
      "\"CSLS metric\"\n",
      "\"MILE improves quality\"\n",
      "\"However, such methods rarely scale to large datasets (e.g., graphs with over 1 million nodes) since they are computationally expensive and often memory intensive\"\n",
      "\"3\"\n",
      "\"retention weights\"\n",
      "\"The optimum value of r for our experiments was found to be 0.65\", \"the best value of b was found to be 5\", \"The weights λ1, λ2, λ3, and λ4 have been set to 3, 2, 50 and 3 respectively for our experiments\" -> how is \"best\"\n",
      "\"improved certifiable robustness\"\n",
      "\"Analysis of classifiers’ robustness to adversarial perturbations.\"\n",
      "\"SGD BN removed\"\n",
      "\"common task\"\n",
      "\"Multilinear Analysis of Image Ensembles: TensorFaces,\"\n",
      "\"universal\"\n",
      "\"It is known that PER can become very expensive in computational time\"\n",
      "\".,!\" or end of sentence. What is called \"structural\"? Note that those punctuation marks are not 100% correlated to sentence structure. For example, \"He hate fruits such as apples, pears, and oranges.\" The mode should jump to the end of sentence rather than the first \",\" when reading \"such\"\n",
      "\"0\" label to real data and \"alpha\"\n",
      "\"downstream tasks\"\n",
      "\"the key observation ...\"\n",
      "\"Learning One Convolutional Layer with Overlapping Patches.\"\n",
      "\"Do GANs actually learn the distribution? an empirical study.\"\n",
      "\"information bottleneck hierarchy\"\n",
      "\"complex system\"\n",
      "\"Markov chains are considered\"\n",
      "\"control\"\n",
      "\"{0...E}\" instead of \"{0, E}\"\n",
      "\"outperforms the baseline by a large margin\" - Figure 4 - overlapping error bars; \"state of the art\"\n",
      "\"approximation\"\n",
      "\"Variational image compression with a scale hyperprior\"\n",
      "\"A\" -> \"AI\"\n",
      "\"advise gradient\"\n",
      "\"explainable representations\"\n",
      "\"supervised\"\n",
      "\"keep moving\"\n",
      "\"periodicity\"\n",
      "\"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\"\n",
      "\"local\"\n",
      "\"similarity matching\"\n",
      "\"attack success\"\n",
      "\"thermodynamic\"\n",
      "\"i\"\n",
      "\"Hierarchical Probabilistic Neural Network Language Model,\"\n",
      "\"match\"\n",
      "\"constrained\"). This metric defines a Riemannian metric between two parameters, by considering the resulting vector field that solve this equation (I guess evaluated at time 0). The authors propose to use the natural gradient associated with that Riemannian metric (Theorem 2). Using exactly that natural gradient would involve solving an optimal transport problem (compute the optimal displacement field) and inverting the corresponding operator. The authors mention that, equivalently, a JKO type step could also be considered to obtain an update for \\theta. The authors propose two distinct approximations, a \"semi-backward Euler formulation\"\n",
      "\"static world CARLA\", section 1). It is unclear how this approach would generalize beyond just staying on the road. How would it handle traffic lights, pedestrians, other drivers, weather variations, and more complex driving tasks than waypoint following by traversing mostly free space? How does the prior generalize to more complex behaviors (e.g, by using more contextual information \\phi)? How robust is the method to noise in the demonstrations, i.e. non-expert or suboptimal behavior? It seems that estimating the generative prior on human behavior might suffer from the same issues as behavior cloning, e.g., the sample inefficiency due to the combinatorial explosion of causal factors explaining complex human behaviors. It might be in fact even harder to estimate that generative model than use a direct discriminative approach (e.g., a modular pipeline), at the cost of reduced flexibility at test time of course. The currently reported sample efficiency (7000 training samples) and near perfect success rate seem to suggest that this (non-standard) version of the CARLA benchmark is too simple (no weather variations, no dynamic obstacles). Comparison to the state of the art (beyond the baselines implemented here) on the original CARLA benchmark seems needed (especially in the \"Nav. dynamic\"\n",
      "\"End to end learning for self-driving cars.\"\n",
      "\"When faced with a non-symmetric matrix, one can resort to the Arnoldi algorithm.\"\n",
      "\"good\"\n",
      "\"neural persistence\", i.e., a topological measure to assign scores to fully-connected layers in a neural network. Essentially, a simplicial complex is constructed by considering neurons as 0-simplices and connections as 1-simplices. Using the (normalized) connection weights then facilitates to define a filtration. Persistent homology (for 0-dim. homology groups) then provides a concise summary of the evolution of the 0-dim. features over the filtration in the form of a barcode. The p-norm of the persistence diagram (containing points (1,w_i)) is then used to define the \"neural persistence\"\n",
      "\"This paper studies the problem of domain division problem...\"\n",
      "\"extra\" degrees of freedom. It looks that the \"latent\" variables are just concaneted to the \"original\"\n",
      "\"We also found...\", page 5 following \"We discovered....\", page 5 following \"It clearly presents...\", page 5 following \"Drawing samples...\" evidence is given only for 1 dimension, page 6 following \"Figure 7(b)...\"\n",
      "\"typical\"\n",
      "\"assumptions\"\n",
      "\"call\" before the present \"response\"\n",
      "\"Multi-Column Deep Neural Networks for Image Classification\"\n",
      "\"Dual Learning\" approach to supervised (and unsupervised) translation problems by making use of additional pretrained mappings for both directions (i.e. primal and dual). These pre-trained mappings (\"agents\") generate targets from the primal to the dual domain, which need to be mapped back to the original input. It is shown that having >=1 additional agents improves training of the BLEU score in standard MT and unsupervised MT tasks. The method is also applied to unsupervised image-to-image \"translation\"\n",
      "\"experimentally\"\n",
      "\"training data\"\n",
      "\"not in the batch\"\n",
      "\"provide a two-timescale network (TTN) architecture that enables LINEAR methods to be used to learn values [...] The approach facilitates use of algorithms developed for the LINEAR setting [...] We prove convergence for TTNs, with particular care given to ensure convergence of the fast LINEAR component.\"\n",
      "\"fast\"\n",
      "\"utility of optimizing the MSPBE\"\n",
      "\"explainable\"\n",
      "\"Anchors: High-Precision Model-Agnostic Explanations\" by Ribeiro et. al. and \"Interpretable & Explorable Approximations of Black Box Models\"\n",
      "\"test set\"\n",
      "\"differential operators can be efficiently computed using Finite Element basis, or derived by Discrete Exterior Calculus\"\n",
      "\"run the algorithm for a few more iterations\"\n",
      "\"Current work..are known\"\n",
      "\"Targeted adversarial examples for black box audio systems\"\n",
      "\"composite\"\n",
      "\"Toruse: Knowledge graph embedding on a lie group.\" arXiv preprint arXiv:1711.05435 (2017).\"\n",
      "\"ZeroInit\"\n",
      "\"Compared to other dynamic reparameterization methods that reallocate non-zero parameters during training, our approach broke free from a few key limitations and achieved much better performance at lower computational cost.\"\n",
      "\"start-of-the-art sparse compression methods.\"\n",
      "\"first dynamic reparameterization method for training convolutional network\"\n",
      "\"explanations\" are simply intuitions (which is related to AnonReviewer3's concern \"Regarding advantages of learning a joint model as opposed to unidirectional mappings\"\n",
      "\"due to time constraints, ..., results will be updated\"\n",
      "\"On Learning Heteroscedastic Noise Models within Differentiable Bayes Filters\"\n",
      "\"planar pushing\"\n",
      "\"sensory deprivation\"\n",
      "\"unseen\"\n",
      "\"step loss\"\n",
      "\"one-step path rewards\"\n",
      "\"large number of different objects\"\n",
      "\"right\"\n",
      "\"Elbo surgery: yet another way to carve up the variational evidence lower bound.\"\n",
      "\"we will run more experiments\", so my review scores haven't changed. I'm glad the authors are planning many revised experiments, and I understand that these take time. It's too bad revised results won't be available before the review revision deadline (tomorrow 11/26). I guess I'm willing to take the author's promises to update in good faith. Thus, I think this is an \"accept\"\n",
      "\"there's no objective function\"\n",
      "\"off-manifold\"\n",
      "\"z\" per task which to capture the commonality in the task instances. Since this leads to an intractable likelihood the authors use the standard ELBO with a Variational Distribution over \"z\"\n",
      "\"variational Bayes neural networks\"\n",
      "\"z\" and has parameters \"a\". They continue their argument in Sec 2.2 that since the weight scoring can be canceled out in the ELBO, the score of the model does not depend on weights \"w\"\n",
      "\"order 1\"\n",
      "\"GRU has become wildly popular in the machine learning community thanks to its performance in machine translation (Britz et al., 2017) ... LSTM has been shown to outperform GRU on neural machine translation (Britz et al., 2017).... specifically unbounded counting, come easy to LSTM networks but not to GRU networks (Weiss et al., 2018).\"\n",
      "\"batchsize x heightout x widthout x stide^2\"\n",
      "\"super convergence\"\n",
      "\"hard\"\n",
      "\"the variance of models obtained by Guassian Process regression is handled implicitely so we tran each model once\"\n",
      "\"best practices\"\n",
      "\"with little extra cost\"\n",
      "\"value of path\" (product of weights along the path) is G-invariant and together with \"activation status of paths\" allows for the definition of an equivalence class. They then build a G-space which has fewer dimensions than the weight space, and proposed g-SGD to optimize the network in this space. In g-SGD gradients are computed normally, then projected to G-space via a sparse matrix in order to update the values of paths. The weights are then updated based on a \"weight allocation method\"\n",
      "\"Improving DNN Robustness to Adversarial Attacks using Jacobian Regularization.\"\n",
      "\"decision boundary loss\"\n",
      "\"DIAL(1) performs worse than SchedNet-Top(1)\"\n",
      "\"relative\"\n",
      "\"For fixed h, the expressiveness is related to the MDP M: 1) if the transition p(xt+1|xt, at)π(at|xt) of the MDP is not ergodic, i.e., it can only visit a subset of observations, then the matrix {h(X1 ), · · · , h(Xt ), · · · } will more possibly be low rank; 2) if the reward is very sparse, the representation matrix will be low rank.\"\n",
      "\"expressiveness\"\n",
      "\"checking algorithm\"\n",
      "\"zero\"\n",
      "\"A\" in A-GEM could stand for \"averaging\" (over all task losses) or \"approximating\"\n",
      "\"Learning Curve Area\"\n",
      "\"The weights of the Bi-LSTM θ, is learned during the search process. The weights θ determines\"\n",
      "\"works on BO for NAS can only tune feed-forward structures\"\n",
      "\"its\"\n",
      "\"marginally above acceptance threshold\"\n",
      "\"Eq. 3 is equivalent to Theorem 1 of [1] for deterministic encoder-decoder pairs\"\n",
      "\"what is the advantage of having d < D?\"\n",
      "\"Neural Audio Synthesis of Musical Notes with WaveNet AutoEncoders\" - Engel et al (2017)). Like the other two related works (WaveGAN - \"Adversarial Audio Synthesis\"\n",
      "\"SCUT-FBP-5500\"\n",
      "\"whole\"\n",
      "\"To strengthen a naïve Occam bound, we use the idea that that deep networks are insensitive to mild... \"   an extra \"that\"\n",
      "\"data-crowd forecaster\"\n",
      "\"evaluation\" after that. (For the moment, please ignore the \"rating\"\n",
      "\"Naive majority\"\n",
      "\"Adversarially Robust Generalization Requires More Data.\"\n",
      "\"structured\" means that instead of just minimizing the L2 norm of the gradients, a \"mahalanobis norm\" is minimized. The covariance matrix is updated continuously to track the \"structure\"\n",
      "\"standard and widely studied\"\n",
      "\"accounts for asynchronous feature sampling\"\n",
      "\"the same underlying distribution Sun et al. (2016)\" -> \"the same underlying distribution (Sun et al. (2016))\"\n",
      "\"Multi-target Unsupervised Domain Adaptation without Exactly Shared Categories\"\n",
      "\"low-rank\"\n",
      "\"learning to learn.\" This extension changes the space in which \"inner-loop\"\n",
      "\"as expected.\"\n",
      "\"current data\"\n",
      "\"Activations\" \"Representation\" and \"Outputs\"\n",
      "\"Adversarial localization network\"\n",
      "\"for model M, given an instance input and a predicted label, what parts of the input are most relevant for making the M choose the predicted label?\"\n",
      "\"uncertainty\"\n",
      "\"G\" and \"F\"\n",
      "\"degenerates\"\n",
      "\"Layer-wise training of deep networks using kernel similarity\"\n",
      "\"to a standard normal distribution \" should be \"according to P\"\n",
      "\"the global min of R_l wrt S_{l-1} can be explicitly identified prior to any training\"\n",
      "\"(1) an underlying dynamical system with unknown latent parameters\"\n",
      "\"The SSIM index over time shows that the C-C method is more effective than C-F method, for C-F method performs better than C-C method in the short term perdiction when ground truth images are provided, but setting sliding window is too time-consuming, much more than the performance increase\"\n",
      "\"New applications of computers in chemistry.\"\n",
      "\"reaction mechanisms\" against quantum chemical calculations). The developed method aims to predict this series of bond changes through a form of reinforcement learning guided with neural networks. In this sense, the setup and formulation seem largely inherited from cited previous papers by Bradshaw et al, 2018 or Kayala & Baldi, 2011 (though they are not used any RL formulation). Organic compounds at each elementary step are represented as molecular graphs, and reactions are thus a series of graph transformations. Each bond change can be considered as \"action\" at that state to form the next states to head for the final product. The method itself seems quite natural: States transitions are shared by an RNN and the hidden states and observations (molecular graphs at each step, and bond changes as actions) are used to learn \"policy\" and \"state transition\"\n",
      "\"Therefore\"\n",
      "\"adversarial\"\n",
      "\"mean reduction in average recall of 11.6\"\n",
      "\"[...] we only need to approximate the dynamical model accurately on the trajectories of the optimal policy\"\n",
      "\"box pushing\"\n",
      "\"value of information\"\n",
      "\"well-behaved\"\n",
      "\"pixel\"\n",
      "\"adv\"\n",
      "\"one approach fits all\"\n",
      "\"interesting\"\n",
      "\"Unsupervised Feature Selection via Nonnegative Spectral Analysis and Redundancy Control\"\n",
      "\"Information retrieval perspective to nonlinear dimensionality reduction for data visualization.\"\n",
      "\"appropriate prior\"\n",
      "\"appropriate\"\n",
      "\"train to convergence\"\n",
      "\"non-linear gain normalization\"\n",
      "\"performances\"\n",
      "\"partially\"\n",
      "\"from\"\n",
      "\"A Hierarchical Latent Structure for Variational Conversation Modeling\"\n",
      "\"stable\"\n",
      "\"reasonable\"\n",
      "\"A dual approach to scalable verification of deep networks.\"\n",
      "\"Ensemble Adversarial Training\" (ICLR2018) and \"Adversarial Logit Pairing\"\n",
      "\"clean\"\n",
      "\"edges\"\n",
      "\"best\"\n",
      "\"approximation\"\n",
      "\"curse of dimensionality\"\n",
      "\" \"we may also consider ... \"\n",
      "\"Semantically decomposing the latent spaces of generative adversarial networks\", and (a bit less starkly in terms of the alignment with the goals of this paper): Huang et al., 2017 \"Stacked generative adversarial networks\"\n",
      "\"our framework assumes that the distribution of persons with sunglasses and that of persons without them is the same,\" The \"distribution of persons\" is not a rigorous definition and is hard to infer what does it actually mean. \"f\" does not appear in the loss terms although it appears under \"min\"\n",
      "\"exterme\"\n",
      "\"training RNNs is hard.\"\n",
      "\"One of the most pressing ...\"\n",
      "\"NLM is a neural realization of (symbolic) logic machines\"\n",
      "\"effective learning rate\"? If the authors mean that regularization just changes the learning rate in some case, that is true. In fact, it is only true while using l2-norm. I looked through the paper, and I couldn't find one. Similarly, I find point #1. to be confusing: why does reducing the scale of the weights increase the effective learning rate? (This confusion carries over to/remains in section 4.1.). The sentence starting (in point #1.) with \"As evidence,\"\n",
      "\"atomic construction\"\n",
      "\"sorting\"\n",
      "\"modeling more complex dependencies\" in the generative case?  Is that really what's going on?  How can we know?  What does \"modeling more complex dependencies\"\n",
      "\"universal\"\n",
      "\"close\"\n",
      "\"Semantic Autoencoder for Zero-Shot Learning\"\n",
      "\"gradient descent in Euclidean space\"\n",
      "\"separable\"\n",
      "\"z will have on element representing a single parameter\"\n",
      "\"The typical approach to Bayesian filtering, where we infer a distribution, ... jointly, forces us to use extremely strong, factorised approximations, and it is legitimate to worry that these strong approximations might meaningfully disrupt the ability of Bayesian filtering to give close-to-optimal updates.   ... we instead consider ... that incorporates factorisation into the problem setting, and therefore requires fewer approximations downstream. \"\n",
      "\"dummy\"\n",
      "\"dimension-free\"\n",
      "\"applied\"\n",
      "\"Fixed MiniBatch\"\n",
      "\"argument extractor\"\n",
      "\"stagwise\"\n",
      "\"Attentional Multilabel Learning over Graphs-A message passing approach.\"\n",
      "\"For CNNs and DNNs, the staleness slows down deeper models much more than shallower counterparts.\"\n",
      "\"bins\"\n",
      "\"derive exact expressions\"\n",
      "\"given that \\nabla f is moderate\": where does this property come from? or is \"given\" meant to be understood as \"provided...\"\n",
      "\"causality-in-mean\"\n",
      "\"Neural Causal Discovery with Learnable Input Noise\" the authors describe a method for automated causal inference under the scenario of a stream of temporally structured random variables (with no missingness and a look-back window of given size).  The proposed approach combines a novel measure of the importance of fidelty in each variable to predictive accuracy of the future system state (\"learnable noise risk\"\n",
      "\"Multi-bin Trainable Linear Unit for Fast Image Restoration Networks\"\n",
      "\"Perceptual losses for real-time style transfer and super-resolution.\"\n",
      "\"tasks\"\n",
      "\"canvas\" networks and \"drawer\" networks based on convolutional neural networks. One of the main ideas is the replacement of the \"canvas\" networks instead of non-differentiable \"renderer\" to end-to-end train the whole model with mean-squared error loss. It seems to be a novel approach to optimize drawing actions. It is reasonable to use separate networks to approximate the behavior of renderer and to fix the parameters of the \"canvas\"\n",
      "\"infection\" and \"future\" in the description of k stating that it is \"the probability that u infects v in the future\"\n",
      "\"using soft instead of hard constraint\"\n",
      "\"Gaussian dropout approximate posterior\"\n",
      "\"critic\"\n",
      "\"pure neuron detector\", which is a high-order moment function of a vector. It can be proved that the pure neuron detector is zero if and only if the vector is equal to the row vector of A^{-1}. Hence, we can \"purify\"\n",
      "\"largely disagree with results from Bartunov et al 2018\"\n",
      "\"complementary\"\n",
      "\"Graph-VAE\"\n",
      "\"instantaneous change of variables\"\n",
      "\"Goodfellow et al. (2016)\" should read \"(Goodfellow et al., 2016)\"\n",
      "\"sensitivity tensor\" or \"credit assignment tensor\" common term?  Because I've never heard them before.  Consider defining them before you discuss it, and using consistent jargon.  Later in Section 2 you seem to call this the \"RTRL tensor\"\n",
      "\"Progress and Compress\"\n",
      "\"while the *elements of the* feature maps themselves display...\"\n",
      "\"Privacy can be quantified by the difficulty of reconstructing raw data via a generative model\"\n",
      "\"missing\"\n",
      "\"Multiple imputation using deep denoising autoencoders.\"\n",
      "\"siloed\"\n",
      "\"hypo\"xenia, \"hypo\"capnia, \"hypo\"tension). This means the authors designed the embedding learning process with a priori knowledge of the downstream tasks, which significantly weakens theirs claim that PHASE learns transferable embeddings. Word embeddings trained on Wikipedia, or ConvNets trained on ImageNet are not designed to be used in a specific type of downstream tasks. What PHASE demonstrates is basically that \"hypo\"\n",
      "\"patch\"\n",
      "\"mutual information\"\n",
      "\"eigenvalue\"\n",
      "\"A progressive batching L-BFGS method for machine learning.\"\n",
      "\"in AGILE the reward model observes only states s_i (either goal states from an expert, or states from the agent acting on the environment) rather than traces (s1, a1),(s2, a2), . . ., learning to reward the agent based on “what” needs to be done rather than according to “how” it must be done.\"\n",
      "\"Local Receptive Fields Based Extreme Learning Machine\"\n",
      "\"optimality\"\n",
      "\"close sets\"\n",
      "\"we limit the size of meta-actions k to 2 because large action spaces may lead to poor convergence\"\n",
      "\"spread-out\"\n",
      "\"On calibration of modern neural networks.\"\n",
      "\"temperature\"\n",
      "\"task modulation\"\n",
      "\"maximally separating prototypes\"\n",
      "\"cat\" and \"dog\" should not be the same as that between \"car1\" and \"car2\"\n",
      "\"actions with a negative $A^\\pi$ may cause instability, especially when one considers training for several epochs at each iteration using the same data\" and demonstrate this with Figure 2. This is not rigorous. If you just reduce all the negative advantage value to zero and calculate its gradient, the method is similar to just use half of step-size in policy gradient. I speculate that if you halve the step-size in \"Policy Gradient\" setting, the results will be similar to the \"Policy Gradient(only positive advantages)\"\n",
      "\"PPO-CMA\"\n",
      "\"Improved techniques for training gans.\"\n",
      "\"in a high level\"\n",
      "\"This trade-off is inevitable given our problem formulation, since we have two sources of information...and they will conflict in some cases.\"\n",
      "\"while relative reachability makes use of known dynamics, it does not benefit from our handcoded featurization\"\n",
      "\"BEGAN (Berthelot et al., 2017) made the first attempt to solve the inverse mapping from x to z using the non-convex optimization\"\n",
      "\"edited\"\n",
      "\"there is no need for reinforcement learning or sophisticated optimal control\"\n",
      "\"grid-cell like\"\n",
      "\"custard apple\"\n",
      "\"Neural programmer-interpreters.\"\n",
      "\"land sweep strategy\"\n",
      "\"VAE-nCRP trade-off is the direct dependency modeling among clusters against the mean-field variational approach\"\n",
      "\"standard space\"\n",
      "\"FLOPS\" in the result seems to measure the speedup, whereas the actual FLOPS should be less when the speed increases. Also, a \"1x\"\n",
      "\"search right\" -> \"search for the right\", \"predict next word\" -> \"predict the next word\"\n",
      "\"negative examples\"\n",
      "\"Fixer\" dataset that they created is interesting. Those edits supposedly make the code better, so modeling those edits could lead to \"better\"\n",
      "\"neural editor\"\n",
      "\"XXX is all you need?\" or \"Is XXX all you need?\"\n",
      "\"we illustrate how our framework can be of significant benefit for a wide variety of important tasks\"\n",
      "\"point in a vector space\"\n",
      "\"worst-case\"\n",
      "\"of adversarial exampleS ...\"\n",
      "\"zero-resource\"\n",
      "\"p(y_t | y_1 ... y_t)\" should be \"p(y_t | y_1 ... y_{t-1})\"\n",
      "\"learning classifiers from only positive and unlabeled data\", KDD 2008; the latter problem setting was proposed in \"presence-only data and the EM algorithm\", Biometrics 2009 and formalized in \"analysis of learning from positive and unlabeled data\"\n",
      "\"adding some noise along samples' latent feature directions\"\n",
      "\"deterministic dropout\"\n",
      "\"conditional model\"\n",
      "\"production malware engine\"\n",
      "\"l_i\"\n",
      "\"empirical\"\n",
      "\"noise-resilience\"\n",
      "\"bad\"\n",
      "\"hard\"\n",
      "\"4.3\"\n",
      "\"...This work presents a new approach to active anomaly detection...\"\n",
      "\"Advances in Neural ...,\", 'NIPS'02\", \"Advances in Neural Information Processing Systems 29\", \"(Nips)\"\n",
      "\"As will be shown in Section X and in \\citet{something}, REINFORCE can be quite sample inefficient\"\n",
      "\"real-world\"\n",
      "\"multi-step learning\"\n",
      "\"This shifts our problem setting to that of a partially observed MDP, as we do not observe the latent state\"\n",
      "\"Learning to poke by poking: Experiential learning of intuitive physics\"\n",
      "\"balance\"\n",
      "\"Fast and Effective Robustness Certification\"\n",
      "\"universal adversarial examples\"\n",
      "\"the classical approach\"\n",
      "\"Then we re-implement ... naively to a codebook strategy\"\n",
      "\".*\"\n",
      "\"Specifically, we choose its equality, then we have\"\n",
      "\"momentum\"\n",
      "\"implementation robustness\"\n",
      "\"Sample-Efficient Deep RL with Generative Adversarial Tree Search\"\n",
      "\"nominal dynamics model\"\n",
      "\"Learn offline\" subsystem while MPC is the \"Plan online\"\n",
      "\"since the goal is to classify the emotional tone as either 1 or 0, the specific contents of the text are not very important here\"\n",
      "\"LSTM: state memory and memory of a single external event\"\n",
      "\"disentangling\"\n",
      "\"classifier\"\n",
      "\"counterfactual reasoning\"\n",
      "\"GPS-like\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "for pair in pair_obj[\"review_rebuttal_pairs\"]:\n",
    "    #print(pair[\"review_text\"])\n",
    "    #res = re.search(\"\\set..?.?al..\", pair[\"review_text\"][\"text\"])\n",
    "    res = re.search(\"\\\".+\\\"\", pair[\"review_text\"][\"text\"])\n",
    "    if res is not None:\n",
    "        print(res.string[res.start():res.end()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "incredible-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  (Zeng et al., 1983\n",
    "# s [Eiter et al.,... 2016\n",
    "# s like Huang et al.,....206\n",
    "# >> 1. ... At\n",
    "#Tong et al. ( ... 2013\n",
    "\n",
    "# shoudl sentences that are under 5 tokens all be merged with next sentence?\n",
    "# Should everything in quotes be treated as a single sentence? yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indie-budget",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review_sentence': 7, 'rebuttal_sentence': 0, 'review_offset': 181, 'rebuttal_offset': 44, 'size': 7}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1971d838b0a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mexact_match\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"exact_matches\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexact_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_match_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"review_offset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_match_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrebuttal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rebuttal_offset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1971d838b0a9>\u001b[0m in \u001b[0;36mget_match_text\u001b[0;34m(overall_text, match, which_offset)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mwhich_sentence_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhich_offset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_offset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_sentence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverall_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhich_sentence_offset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhich_offset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhich_offset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpair_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review_rebuttal_pairs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "PAIR_FILE = \"review_rebuttal_pair_dataset_debug/traindev_train.json\"\n",
    "\n",
    "with open(PAIR_FILE, 'r') as f:\n",
    "    pair_obj = json.load(f)\n",
    "\n",
    "def get_match_text(overall_text, match, which_offset):\n",
    "    overall_str = overall_text[\"text\"]\n",
    "    which_sentence_offset = which_offset.replace(\"_offset\", \"_sentence\")\n",
    "    sentence = overall_text[\"sentences\"][match[which_sentence_offset]]\n",
    "    return sentence[match[which_offset]:match[which_offset]+match[\"size\"]]\n",
    "    \n",
    "for pair in pair_obj[\"review_rebuttal_pairs\"]:\n",
    "    review = pair[\"review_text\"]\n",
    "    rebuttal = pair[\"rebuttal_text\"]\n",
    "    for exact_match in pair[\"exact_matches\"]:\n",
    "        print(exact_match)\n",
    "        print(get_match_text(review, exact_match, \"review_offset\"))\n",
    "        print(get_match_text(rebuttal, exact_match, \"rebuttal_offset\"))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "complete-spice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJgjH5LY37\n",
      "Please refer to our top-level comment.\n",
      "\n",
      "H1g7-dMz3m\n",
      "Thank you for your thoughtful feedback!\n",
      "\n",
      "B1la-jxRhQ\n",
      "Thank you for your review. We are glad to see that you liked the paper and it's contributions.\n",
      "\n",
      "B1eY8B3_3X\n",
      "Thank you for your encouraging feedback.\n",
      "\n",
      "HkegBTQcnm\n",
      "We thank the reviewer for their time and appreciation of our work.\n",
      "\n",
      "HJe-8Pr93m\n",
      "Thank you for your review. We have updated the references in the revised version as you requested.\n",
      "\n",
      "rkgEmITAiX\n",
      "Thank you for your kind review.\n",
      "\n",
      "\n",
      "BJgPWcE0hQ\n",
      "Thank you for your review.\n",
      "\n",
      "S1gffzlahX\n",
      "We thank the reviewer for the appreciation and the supportive comments.\n",
      "\n",
      "BJl-oTGeaX\n",
      "We thank the reviewer for their constructive feedback.\n",
      "\n",
      "SkeOpvO227\n",
      "We thank the reviewer for their encouraging words and will correct the errors of expression.\n",
      "\n",
      "Byg1SllT37\n",
      "Thank you for the comments. We have fixed the typos in our revision.\n",
      "\n",
      "SkgLoB3p3Q\n",
      "We thank the reviewer for their comments and appreciate the support for our work.\n",
      "\n",
      "B1xX4-Eq3m\n",
      "Thank you for your time to read and evaluate our paper. \n",
      "\n",
      "B1l_Q1cgTX\n",
      "Thank you for your time and review of our paper. \n",
      "\n",
      "H1l2AeXanm\n",
      "Thank you for this review. We will be sure to incorporate your comment in a revision of the paper.\n",
      "\n",
      "Bke-NGHlTQ\n",
      "We thank the reviewer for the kind comments. We have updated the manuscript to fix typos.\n",
      "\n",
      "r1llrOIv2Q\n",
      "Thanks for the comments! We will improve the writing and make the main contributions more clear.\n",
      "\n",
      "Hkx5PKC3hX\n",
      "Thank you for checking the derivations. We appreciate the positive comments.\n",
      "\n",
      "HJxBD9g52X\n",
      "We thank the reviewer for his remarks and positive assessment of our work.\n",
      "\n",
      "SklYe2qunm\n",
      "We thank the reviewer for the kind comments.\n",
      "\n",
      "rkl_eOltTX\n",
      "We thank you for taking time to review our work.\n",
      "\n",
      "Hkg6Ixk93Q\n",
      "We thank the reviewer for the feedback. We are glad you liked the paper.\n",
      "\n",
      "\n",
      "HJeb-tr93Q\n",
      "Thank you very much for the valuable feedback!\n",
      "\n",
      "Hklpflm6h7\n",
      "We appreciate the reviewer’s positive comments about our work.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for pair in pair_obj[\"review_rebuttal_pairs\"]:\n",
    "    if len(pair[\"rebuttal_text\"][\"text\"]) < 100:\n",
    "        print(pair[\"review_sid\"])\n",
    "        print(pair[\"rebuttal_text\"][\"text\"])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-castle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
